{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar objeto do ticker\n",
    "ticker_data = yf.Ticker(\"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Não Funciona ####\n",
    "# # Acessar fast_info\n",
    "info = ticker_data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_symbol_recommendations = ticker_data.recommendations\n",
    "# yahoo_symbol_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividendos\n",
    "cashflow = ticker_data.cashflow\n",
    "# cashflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notícias\n",
    "balance_sheet = ticker_data.balance_sheet\n",
    "# balance_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_symbol_sustainability = ticker_data.sustainability\n",
    "# yahoo_symbol_sustainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventos corporativos\n",
    "calendar = ticker_data.calendar\n",
    "# calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Datas disponíveis para opções\n",
    "# options_dates = ticker_data.options\n",
    "# print(\"Datas de opções:\", options_dates)\n",
    "\n",
    "# # Obter opções para uma data específica\n",
    "# options = ticker_data.option_chain(options_dates[0])\n",
    "# print(\"Opções de compra (calls):\", options.calls)\n",
    "# print(\"Opções de venda (puts):\", options.puts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mnow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informações financeiras mais detalhadas da empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dados de sustentabilidade\n",
    "# sustainability = ticker_data.sustainability\n",
    "# print(sustainability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informações de ESG (Environmental, Social, Governance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ações em circulação\n",
    "# shares = ticker_data.shares\n",
    "# print(\"Ações em circulação:\", shares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenha informações sobre ações em circulação e histórico de splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principais investidores institucionais\n",
    "inst_holders = ticker_data.institutional_holders\n",
    "# inst_holders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados sobre investidores institucionais e sua participação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principais investidores institucionais\n",
    "holders = ticker_data.major_holders\n",
    "# holders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_data_history(symbol : str, period : str, interval: str, start = '1900-01-01', end = datetime.now(), prepost : bool = True):\n",
    "        '''\n",
    "        Data collection from yahoo\n",
    "\n",
    "        Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime, inclusive. Default is 1900-01-01 E.g. for start=\"2020-01-01\", the first data point will be on \"2020-01-01\"\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime, exclusive. Default is now E.g. for end=\"2023-01-01\", the last data point will be on \"2022-12-31\"\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results? Default is False\n",
    "        debug: bool\n",
    "            If passed as False, will suppress error message printing to console.\n",
    "        '''\n",
    "        yahoo_data_history = yf.Ticker(symbol).history(period=period, interval=interval, start=start, end=end, prepost=prepost)\n",
    "        return yahoo_data_history\n",
    "\n",
    "history = get_yahoo_data_history(symbol=\"MSFT\",period='1y', interval='1d', end = datetime.now(), prepost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned Data: {'data': {'companies': []}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the endpoint and your API key\n",
    "url = \"https://api.simplywall.st/graphql\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer sws:ZGE4YzBlNzItMTg2Ni00Y2Y5LWI3YTktYzAxODcyZGEwZjE3OmFjODUzODRhZDUzNGMwMzY=\",\n",
    "    \"Content-Type\": \"application/json\",  # Required for JSON body\n",
    "}\n",
    "\n",
    "# Define the GraphQL query and variables\n",
    "query = \"\"\"\n",
    "query Companies($exchange: String!, $offset: Int!, $limit: Int!) {\n",
    "  companies(exchange: $exchange, offset: $offset, limit: $limit) {\n",
    "    id\n",
    "    exchangeSymbol\n",
    "    tickerSymbol\n",
    "    name\n",
    "    marketCapUSD\n",
    "    primaryIndustry { name }\n",
    "    secondaryIndustry { name }\n",
    "    tertiaryIndustry { name }\n",
    "    market { name iso2 }\n",
    "    closingPrices\n",
    "    statements { name title area type value outcome description state severity outcomeName }\n",
    "    listings { id exchangeSymbol tickerSymbol name marketCapUSD primaryIndustry { name } secondaryIndustry { name } tertiaryIndustry { name } market { name iso2 } closingPrices }\n",
    "    owners { name type sharesHeld percentOfSharesOutstanding holdingDate periodStartDate periodEndDate }\n",
    "    insiderTransactions { type ownerName ownerType description tradeDateMin tradeDateMax shares priceMin priceMax transactionValue percentageSharesTraded }\n",
    "    members { age name title tenure compensation }\n",
    "    active classificationStatus\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Define the variables for the query\n",
    "variables = {\n",
    "    \"exchange\": \"NYSE\",  # Try changing to \"NYSE\" or another exchange\n",
    "    \"offset\": 20,         # Try adjusting this value (e.g., 10 or 20)\n",
    "    \"limit\": 100          # Adjust limit to fetch more results\n",
    "}\n",
    "\n",
    "# Create the request payload\n",
    "payload = {\n",
    "    \"query\": query,\n",
    "    \"variables\": variables\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        print(\"No companies found with the given parameters.\")\n",
    "    else:\n",
    "        print(\"Returned Data:\", data)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando instalação do TA-Lib no Windows...\n",
      "O arquivo TA_Lib-0.5.1-cp311-cp311-win_amd64.whl já existe. Pulando o download.\n",
      "Instalando TA_Lib-0.5.1-cp311-cp311-win_amd64.whl...\n",
      "TA-Lib instalado com sucesso!\n",
      "Arquivo x:\\Taurus\\market-analyzer\\backend\\test\\TA_Lib-0.5.1-cp311-cp311-win_amd64.whl removido após a instalação.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "\n",
    "class TALibInstaller:\n",
    "    def install_ta_lib_windows(self):\n",
    "        \"\"\"Automatiza a instalação do TA-Lib no Windows.\"\"\"\n",
    "        print(\"Iniciando instalação do TA-Lib no Windows...\")\n",
    "\n",
    "        # URL do arquivo .whl (atualize conforme necessário)\n",
    "        talib_url = \"https://github.com/cgohlke/talib-build/releases/download/v0.5.1/TA_Lib-0.5.1-cp311-cp311-win_amd64.whl\"\n",
    "        talib_whl = talib_url.split(\"/\")[-1]  # Nome do arquivo\n",
    "\n",
    "        # Caminho local para salvar o arquivo .whl\n",
    "        local_path = os.path.join(os.getcwd(), \"libraries\")\n",
    "\n",
    "        # Fazer o download do arquivo .whl\n",
    "        if not os.path.exists(local_path):\n",
    "            print(f\"Baixando {talib_whl} de {talib_url}...\")\n",
    "            response = requests.get(talib_url, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(local_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(chunk_size=1024):\n",
    "                        f.write(chunk)\n",
    "                print(f\"Download concluído: {local_path}\")\n",
    "            else:\n",
    "                print(f\"Erro ao baixar {talib_url}: {response.status_code}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"O arquivo {talib_whl} já existe. Pulando o download.\")\n",
    "\n",
    "        # Instalar o arquivo .whl com pip\n",
    "        print(f\"Instalando {talib_whl}...\")\n",
    "        try:\n",
    "            subprocess.check_call([\"pip\", \"install\", local_path])\n",
    "            print(\"TA-Lib instalado com sucesso!\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Erro durante a instalação: {e}\")\n",
    "            return False\n",
    "\n",
    "        # Remover o arquivo .whl após a instalação (opcional)\n",
    "        if os.path.exists(local_path):\n",
    "            os.remove(local_path)\n",
    "            print(f\"Arquivo {local_path} removido após a instalação.\")\n",
    "        return True\n",
    "\n",
    "\n",
    "# Uso\n",
    "if __name__ == \"__main__\":\n",
    "    installer = TALibInstaller()\n",
    "    installer.install_ta_lib_windows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "\n",
    "class CandlesPatterns:\n",
    "    \"\"\"\n",
    "    Detect all candlestick patterns using TA-Lib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.result_candles_history_df = pd.DataFrame(columns=['Pattern', 'Signal', 'Relevance', 'Stoploss'])\n",
    "        self.result_candles_df = pd.DataFrame(columns=['Pattern', 'Signal', 'Relevance', 'Stoploss'])\n",
    "        \n",
    "        \n",
    "    def detect_pattern(self, data: pd.DataFrame, pattern_function, pattern_name: str):\n",
    "        \"\"\"\n",
    "        General method to detect a specific candlestick pattern.\n",
    "        \"\"\"\n",
    "        data_pass = data\n",
    "\n",
    "        detection = pattern_function(data_pass['Open'], data_pass['High'], data_pass['Low'], data_pass['Close'])\n",
    "\n",
    "        non_zero_detection = detection[detection != 0]\n",
    "        if not non_zero_detection.empty:\n",
    "            for date, signal in non_zero_detection.items():\n",
    "                # Cálculo do Stoploss baseado no padrão\n",
    "                if pattern_name in [\n",
    "                    \"doji\", \"dragonfly_doji\", \"gravestone_doji\", \"engulfing\",\n",
    "                    \"morning_star\", \"evening_star\", \"marubozu\", \"harami\",\n",
    "                    \"harami_cross\", \"kicking\", \"kicking_by_length\", \"tasuki_gap\",\n",
    "                    \"gap_side_by_side_white\", \"counter_attack\", \"piercing\",\n",
    "                    \"dark_cloud_cover\", \"tri_star\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'Low'],5) if signal > 0 else round(data_pass.loc[date, 'High'],5)\n",
    "                elif pattern_name in [\n",
    "                    \"morning_doji_star\", \"hammer\", \"inverted_hammer\",\n",
    "                    \"thrusting\", \"matching_low\", \"three_white_soldiers\",\n",
    "                    \"three_outside\", \"three_stars_in_south\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'Low'],5)\n",
    "                elif pattern_name in [\n",
    "                    \"evening_doji_star\", \"hanging_man\", \"shooting_star\",\n",
    "                    \"on_neck\", \"in_neck\", \"three_black_crows\",\n",
    "                    \"three_inside\", \"advance_block\", \"stalled_pattern\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'High'],5)\n",
    "                else:\n",
    "                    stoploss = None\n",
    "\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'Pattern': [pattern_name],\n",
    "                    'Signal': [signal],\n",
    "                    'Relevance': ['Flat'],\n",
    "                    'Stoploss': [stoploss],\n",
    "                }, index=[date])\n",
    "\n",
    "                self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
    "\n",
    "                self.result_candles_df = self.result_candles_df[self.result_candles_df['Pattern'] != pattern_name]\n",
    "                self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n",
    "\n",
    "        return detection\n",
    "\n",
    "    def doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDOJI, \"doji\")\n",
    "\n",
    "    def dragonfly_doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDRAGONFLYDOJI, \"dragonfly_doji\")\n",
    "\n",
    "    def gravestone_doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLGRAVESTONEDOJI, \"gravestone_doji\")\n",
    "\n",
    "    def engulfing(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLENGULFING, \"engulfing\")\n",
    "\n",
    "    def morning_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLMORNINGSTAR, \"morning_star\")\n",
    "\n",
    "    def evening_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLEVENINGSTAR, \"evening_star\")\n",
    "\n",
    "    def morning_doji_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMORNINGDOJISTAR, \"morning_doji_star\")\n",
    "\n",
    "    def evening_doji_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLEVENINGDOJISTAR, \"evening_doji_star\")\n",
    "\n",
    "    def hammer(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLHAMMER, \"hammer\")\n",
    "\n",
    "    def inverted_hammer(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLINVERTEDHAMMER, \"inverted_hammer\")\n",
    "\n",
    "    def hanging_man(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLHANGINGMAN, \"hanging_man\")\n",
    "\n",
    "    def shooting_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLSHOOTINGSTAR, \"shooting_star\")\n",
    "\n",
    "    def marubozu(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMARUBOZU, \"marubozu\")\n",
    "\n",
    "    def harami(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLHARAMI, \"harami\")\n",
    "\n",
    "    def harami_cross(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLHARAMICROSS, \"harami_cross\")\n",
    "\n",
    "    def spinning_top(self, data: pd.DataFrame):\n",
    "        '''\n",
    "        NEED FIBONACCI\n",
    "        '''\n",
    "        return self.detect_pattern(data, talib.CDLSPINNINGTOP, \"spinning_top\")\n",
    "\n",
    "    def kicking(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLKICKING, \"kicking\")\n",
    "\n",
    "    def kicking_by_length(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLKICKINGBYLENGTH, \"kicking_by_length\")\n",
    "\n",
    "    def tasuki_gap(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTASUKIGAP, \"tasuki_gap\")\n",
    "\n",
    "    def gap_side_by_side_white(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLGAPSIDESIDEWHITE, \"gap_side_by_side_white\")\n",
    "\n",
    "    def counter_attack(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLCOUNTERATTACK, \"counter_attack\")\n",
    "\n",
    "    def piercing(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLPIERCING, \"piercing\")\n",
    "\n",
    "    def dark_cloud_cover(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDARKCLOUDCOVER, \"dark_cloud_cover\")\n",
    "\n",
    "    def tri_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTRISTAR, \"tri_star\")\n",
    "\n",
    "    def on_neck(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLONNECK, \"on_neck\")\n",
    "\n",
    "    def in_neck(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLINNECK, \"in_neck\")\n",
    "\n",
    "    def thrusting(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTHRUSTING, \"thrusting\")\n",
    "\n",
    "    def matching_low(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMATCHINGLOW, \"matching_low\")\n",
    "\n",
    "    def three_black_crows(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3BLACKCROWS, \"three_black_crows\")\n",
    "\n",
    "    def three_white_soldiers(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3WHITESOLDIERS, \"three_white_soldiers\")\n",
    "\n",
    "    def three_inside(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3INSIDE, \"three_inside\")\n",
    "\n",
    "    def three_outside(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3OUTSIDE, \"three_outside\")\n",
    "\n",
    "    def three_stars_in_south(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3STARSINSOUTH, \"three_stars_in_south\")\n",
    "\n",
    "    def advance_block(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLADVANCEBLOCK, \"advance_block\")\n",
    "\n",
    "    def stalled_pattern(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLSTALLEDPATTERN, \"stalled_pattern\")\n",
    "\n",
    "    # def abandoned_baby(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLABANDONEDBABY, \"abandoned_baby\")\n",
    "\n",
    "    # def unique_3_river(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLUNIQUE3RIVER, \"unique_3_river\")\n",
    "\n",
    "    # def belt_hold(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLBELTHOLD, \"belt_hold\")\n",
    "\n",
    "    # def separating_lines(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLSEPARATINGLINES, \"Separating Lines\")\n",
    "\n",
    "    # def upside_gap_two_crows(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLUPSIDEGAP2CROWS, \"Upside Gap Two Crows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_22476\\45596638.py:56: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_22476\\45596638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_22476\\45596638.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_22476\\45596638.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Detected Patterns with Stoploss:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Stoploss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-18 00:00:00-04:00</th>\n",
       "      <td>advance_block</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>543.35483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-18 00:00:00-04:00</th>\n",
       "      <td>counter_attack</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>424.30297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-22 00:00:00-04:00</th>\n",
       "      <td>dark_cloud_cover</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>385.83253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>dragonfly_doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-02 00:00:00-04:00</th>\n",
       "      <td>engulfing</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>540.16963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-20 00:00:00-04:00</th>\n",
       "      <td>evening_doji_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>445.94876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26 00:00:00-05:00</th>\n",
       "      <td>evening_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>502.30678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24 00:00:00-05:00</th>\n",
       "      <td>gap_side_by_side_white</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>447.15796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28 00:00:00-04:00</th>\n",
       "      <td>gravestone_doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>517.76285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-17 00:00:00-04:00</th>\n",
       "      <td>hammer</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>522.25921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-06 00:00:00-04:00</th>\n",
       "      <td>hanging_man</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>530.28146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>harami</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>harami_cross</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-18 00:00:00-04:00</th>\n",
       "      <td>in_neck</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>428.77127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-24 00:00:00-04:00</th>\n",
       "      <td>inverted_hammer</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.14615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-03 00:00:00-04:00</th>\n",
       "      <td>marubozu</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.13756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13 00:00:00-04:00</th>\n",
       "      <td>matching_low</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>514.75195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-22 00:00:00-04:00</th>\n",
       "      <td>morning_doji_star</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>369.50896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12 00:00:00-04:00</th>\n",
       "      <td>morning_star</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>504.39004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-11 00:00:00-04:00</th>\n",
       "      <td>on_neck</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>505.39713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-25 00:00:00-04:00</th>\n",
       "      <td>piercing</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>421.58109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-18 00:00:00-04:00</th>\n",
       "      <td>shooting_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>510.53284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-21 00:00:00-04:00</th>\n",
       "      <td>spinning_top</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01 00:00:00-05:00</th>\n",
       "      <td>stalled_pattern</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>434.13643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 00:00:00-05:00</th>\n",
       "      <td>tasuki_gap</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>382.23807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-02 00:00:00-04:00</th>\n",
       "      <td>three_inside</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.49530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-03 00:00:00-04:00</th>\n",
       "      <td>three_outside</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.13756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-13 00:00:00-05:00</th>\n",
       "      <td>three_white_soldiers</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>456.39158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01 00:00:00-04:00</th>\n",
       "      <td>thrusting</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>376.05613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-27 00:00:00-05:00</th>\n",
       "      <td>tri_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>447.90527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Pattern Signal Relevance   Stoploss\n",
       "2024-06-18 00:00:00-04:00           advance_block   -100      Flat  543.35483\n",
       "2023-08-18 00:00:00-04:00          counter_attack    100      Flat  424.30297\n",
       "2022-07-22 00:00:00-04:00        dark_cloud_cover   -100      Flat  385.83253\n",
       "2024-07-01 00:00:00-04:00                    doji    100      Flat  539.04680\n",
       "2024-07-01 00:00:00-04:00          dragonfly_doji    100      Flat  539.04680\n",
       "2024-07-02 00:00:00-04:00               engulfing    100      Flat  540.16963\n",
       "2023-07-20 00:00:00-04:00       evening_doji_star   -100      Flat  445.94876\n",
       "2024-02-26 00:00:00-05:00            evening_star   -100      Flat  502.30678\n",
       "2023-11-24 00:00:00-05:00  gap_side_by_side_white    100      Flat  447.15796\n",
       "2024-03-28 00:00:00-04:00         gravestone_doji    100      Flat  517.76285\n",
       "2024-05-17 00:00:00-04:00                  hammer    100      Flat  522.25921\n",
       "2024-06-06 00:00:00-04:00             hanging_man   -100      Flat  530.28146\n",
       "2024-07-01 00:00:00-04:00                  harami    100      Flat  539.04680\n",
       "2024-07-01 00:00:00-04:00            harami_cross    100      Flat  539.04680\n",
       "2023-08-18 00:00:00-04:00                 in_neck   -100      Flat  428.77127\n",
       "2024-06-24 00:00:00-04:00         inverted_hammer    100      Flat  539.14615\n",
       "2024-07-03 00:00:00-04:00                marubozu    100      Flat  545.13756\n",
       "2024-05-13 00:00:00-04:00            matching_low    100      Flat  514.75195\n",
       "2021-03-22 00:00:00-04:00       morning_doji_star    100      Flat  369.50896\n",
       "2024-03-12 00:00:00-04:00            morning_star    100      Flat  504.39004\n",
       "2024-03-11 00:00:00-04:00                 on_neck   -100      Flat  505.39713\n",
       "2023-09-25 00:00:00-04:00                piercing    100      Flat  421.58109\n",
       "2024-03-18 00:00:00-04:00           shooting_star   -100      Flat  510.53284\n",
       "2024-06-21 00:00:00-04:00            spinning_top    100      Flat        NaN\n",
       "2022-02-01 00:00:00-05:00         stalled_pattern   -100      Flat  434.13643\n",
       "2022-11-14 00:00:00-05:00              tasuki_gap    100      Flat  382.23807\n",
       "2024-07-02 00:00:00-04:00            three_inside    100      Flat  545.49530\n",
       "2024-07-03 00:00:00-04:00           three_outside    100      Flat  545.13756\n",
       "2023-12-13 00:00:00-05:00    three_white_soldiers    100      Flat  456.39158\n",
       "2022-09-01 00:00:00-04:00               thrusting   -100      Flat  376.05613\n",
       "2023-11-27 00:00:00-05:00                tri_star   -100      Flat  447.90527"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "start, end = '2015-01-01', '2024-07-05'\n",
    "\n",
    "data = yf.Ticker('SPY').history(period='1y', interval='1d', start=start, end=end)\n",
    "\n",
    "cm = CandlesPatterns()\n",
    "\n",
    "# Loop para detectar padrões\n",
    "for candle_function in dir(cm):\n",
    "    if (not candle_function.startswith(\"__\") and \n",
    "        callable(getattr(cm, candle_function)) and \n",
    "        candle_function != \"detect_pattern\"):\n",
    "        pattern_function = getattr(cm, candle_function)\n",
    "        try:\n",
    "            candle_result = pattern_function(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting pattern {candle_function}: {e}\")\n",
    "\n",
    "# Verificar padrões detectados e valores de stoploss\n",
    "print(\"\\nAll Detected Patterns with Stoploss:\")\n",
    "cm.result_candles_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class ParamsOptimization():\n",
    "    \"\"\"\n",
    "    A class for optimizing technical indicators' parameters and evaluating strategy performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ticker, market_type, timeframe):\n",
    "        self.ticker = ticker\n",
    "        self.market_type = market_type\n",
    "        self.timeframe = timeframe\n",
    "        self.best_params\n",
    "\n",
    "    def fetch_data(self, ticker):\n",
    "        \"\"\"\n",
    "        Simulate fetching market data for the given ticker.\n",
    "        Replace this method with the actual data retrieval logic.\n",
    "        \"\"\"\n",
    "        # Simulate historical data\n",
    "        np.random.seed(42)\n",
    "        size = 1000  # Simulated number of rows\n",
    "        data = pd.DataFrame({\n",
    "            \"close\": np.random.uniform(100, 200, size),\n",
    "            \"volume\": np.random.randint(1000, 5000, size)\n",
    "        })\n",
    "        return data\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Run optimization for all strategies.\n",
    "        \"\"\"\n",
    "        tickers = [self.ticker] if isinstance(self.ticker, str) else self.ticker\n",
    "        all_results = []\n",
    "\n",
    "        for ticker in tickers:\n",
    "            data = self.fetch_data(ticker)\n",
    "            crossover_params = self.optimize_crossover(data, ticker)\n",
    "            bbands_params = self.optimize_bbands(data, ticker)\n",
    "            all_results.append(pd.concat([crossover_params, bbands_params], axis=1))\n",
    "\n",
    "        self.best_params = pd.concat(all_results, ignore_index=True)\n",
    "        return self.best_params\n",
    "\n",
    "    def optimize_crossover(self, data, ticker):\n",
    "        \"\"\"\n",
    "        Optimize EMA crossover strategy.\n",
    "        \"\"\"\n",
    "        ema1_periods = [10, 15, 20]\n",
    "        ema2_periods = [25, 30, 50]\n",
    "        ema3_periods = [100, 150, 200]\n",
    "\n",
    "        combinations = list(itertools.product(ema1_periods, ema2_periods, ema3_periods))\n",
    "\n",
    "        # Parallel execution for speed\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.simulate_crossover)(\n",
    "            data, ticker, l1, l2, l3) for l1, l2, l3 in tqdm(combinations, desc=\"Optimizing EMA Crossover\"))\n",
    "\n",
    "        # Combine results into a DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        best_result = results_df.loc[results_df['Expectancy'].idxmax()]\n",
    "\n",
    "        return best_result\n",
    "\n",
    "    def simulate_crossover(self, data, ticker, l1, l2, l3):\n",
    "        \"\"\"\n",
    "        Simulate crossover strategy and calculate metrics.\n",
    "        \"\"\"\n",
    "        # Calculate EMAs\n",
    "        data['ema1'] = talib.EMA(data['close'], timeperiod=l1)\n",
    "        data['ema2'] = talib.EMA(data['close'], timeperiod=l2)\n",
    "        data['ema3'] = talib.EMA(data['close'], timeperiod=l3)\n",
    "\n",
    "        # Generate signals\n",
    "        data['signal'] = np.where((data['ema1'] > data['ema2']) & (data['ema2'] > data['ema3']), 1,\n",
    "                                  np.where((data['ema1'] < data['ema2']) & (data['ema2'] < data['ema3']), -1, 0))\n",
    "        data['returns'] = data['close'].pct_change() * data['signal'].shift(1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        sharpe = self.calculate_sharpe(data['returns'])\n",
    "        max_drawdown = self.calculate_max_drawdown(data['returns'])\n",
    "        expectancy = self.calculate_expectancy(data['returns'])\n",
    "\n",
    "        return {\n",
    "            'Ticker': ticker,\n",
    "            'Best_EMA1': l1,\n",
    "            'Best_EMA2': l2,\n",
    "            'Best_EMA3': l3,\n",
    "            'Sharpe': sharpe,\n",
    "            'Max_Drawdown': max_drawdown,\n",
    "            'Expectancy': expectancy\n",
    "        }\n",
    "\n",
    "    def optimize_bbands(self, data, ticker):\n",
    "        \"\"\"\n",
    "        Optimize Bollinger Bands strategy.\n",
    "        \"\"\"\n",
    "        sma_periods = [10, 15, 20]\n",
    "        std_devs = [1, 2, 3]\n",
    "\n",
    "        combinations = list(itertools.product(sma_periods, std_devs))\n",
    "\n",
    "        # Parallel execution for speed\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.simulate_bbands)(\n",
    "            data, ticker, period, std) for period, std in tqdm(combinations, desc=\"Optimizing Bollinger Bands\"))\n",
    "\n",
    "        # Combine results into a DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        best_result = results_df.loc[results_df['Expectancy'].idxmax()]\n",
    "\n",
    "        return best_result\n",
    "\n",
    "    def simulate_bbands(self, data, ticker, period, std):\n",
    "        \"\"\"\n",
    "        Simulate Bollinger Bands strategy and calculate metrics.\n",
    "        \"\"\"\n",
    "        # Calculate Bollinger Bands\n",
    "        upperband, middleband, lowerband = talib.BBANDS(\n",
    "            data['close'], timeperiod=period, nbdevup=std, nbdevdn=std, matype=0\n",
    "        )\n",
    "\n",
    "        # Generate signals\n",
    "        data['signal'] = np.where(data['close'] < lowerband, 1,\n",
    "                                  np.where(data['close'] > upperband, -1, 0))\n",
    "        data['returns'] = data['close'].pct_change() * data['signal'].shift(1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        sharpe = self.calculate_sharpe(data['returns'])\n",
    "        max_drawdown = self.calculate_max_drawdown(data['returns'])\n",
    "        expectancy = self.calculate_expectancy(data['returns'])\n",
    "\n",
    "        return {\n",
    "            'Ticker': ticker,\n",
    "            'Best_Period': period,\n",
    "            'Best_Std': std,\n",
    "            'Sharpe': sharpe,\n",
    "            'Max_Drawdown': max_drawdown,\n",
    "            'Expectancy': expectancy\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_sharpe(returns, risk_free_rate=0.025):\n",
    "        \"\"\"\n",
    "        Calculate Sharpe Ratio.\n",
    "        \"\"\"\n",
    "        mean_return = returns.mean()\n",
    "        std_dev = returns.std()\n",
    "        if std_dev == 0:\n",
    "            return 0\n",
    "        return (mean_return - risk_free_rate) / std_dev\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_max_drawdown(returns):\n",
    "        \"\"\"\n",
    "        Calculate Max Drawdown.\n",
    "        \"\"\"\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        running_max = cumulative.cummax()\n",
    "        drawdown = running_max - cumulative\n",
    "        return drawdown.max()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_expectancy(returns):\n",
    "        \"\"\"\n",
    "        Calculate Expectancy.\n",
    "        \"\"\"\n",
    "        wins = returns[returns > 0]\n",
    "        losses = returns[returns < 0]\n",
    "        win_rate = len(wins) / len(returns) if len(returns) > 0 else 0\n",
    "        loss_rate = 1 - win_rate\n",
    "        avg_win = wins.mean() if len(wins) > 0 else 0\n",
    "        avg_loss = losses.mean() if len(losses) > 0 else 0\n",
    "        return (win_rate * avg_win) - (loss_rate * avg_loss)\n",
    "\n",
    "\n",
    "\n",
    "# # Instanciar e otimizar\n",
    "# optimizer = ParamsOptimization(ticker=[\"AAPL\", \"GOOG\"], market_type=\"stocks\", timeframe=\"1d\")\n",
    "# best_params = optimizer.optimize()\n",
    "\n",
    "# # Exibir resultados\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "\n",
    "class TrendMetrics():\n",
    "    \"\"\"\n",
    "    A class that encapsulates technical analysis metrics using TA-Lib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.result_df = pd.DataFrame(columns=['function', 'signal'])\n",
    "        self.crossover_info = pd.DataFrame(columns=['function', 'signal', 'period_low', 'period_mid', 'period_high', 'ema_low', 'ema_mid', 'ema_high'])\n",
    "        self.sma_bands_info = pd.DataFrame(columns=['function', 'signal', 'period', 'std', 'lower_band', 'middle_band', 'upper_band'])\n",
    "        self.rsi_info = pd.DataFrame(columns=['function', 'signal', 'period', 'upper_level', 'lower_level'])\n",
    "\n",
    "    def get_crossover(self, data: pd.DataFrame, l1: int, l2: int, l3: int):\n",
    "        \"\"\"\n",
    "        This function measures the crossover of 3 EMAs using TA-Lib.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - l1, l2, l3: Periods for the 3 EMAs.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.crossover_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "        period_low, period_mid, period_high = l1, l2, l3\n",
    "        \n",
    "        # Compute EMAs\n",
    "        ema1 = talib.EMA(data['Close'], timeperiod=l1)\n",
    "        ema2 = talib.EMA(data['Close'], timeperiod=l2)\n",
    "        ema3 = talib.EMA(data['Close'], timeperiod=l3)\n",
    "\n",
    "        # Current values\n",
    "        ema_low, ema_mid, ema_high = ema1.iloc[-1], ema2.iloc[-1], ema3.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if ema_low > ema_mid > ema_high:\n",
    "            crossover_signal = 'Buy'\n",
    "        elif ema_low < ema_mid < ema_high:\n",
    "            crossover_signal = 'Sell'\n",
    "        else:\n",
    "            crossover_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['Crossover'],\n",
    "            'signal': [crossover_signal]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        # Save result\n",
    "        self.crossover_info = pd.concat([self.crossover_info, pd.DataFrame({\n",
    "            'function': ['Crossover'],\n",
    "            'signal': [crossover_signal],\n",
    "            'period_low': [period_low],\n",
    "            'period_mid': [period_mid],\n",
    "            'period_high': [period_high],\n",
    "            'ema1_now': [ema_low],\n",
    "            'ema2_now': [ema_mid],\n",
    "            'ema3_now': [ema_high],\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    def get_sma_bands(self, data: pd.DataFrame, length: int=15, std_dev: int = 1):\n",
    "        \"\"\"\n",
    "        This function calculates Bollinger Bands and detects signals based on them.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - length: SMA period.\n",
    "        - std_dev: Number of standard deviations for the bands.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.bbands_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "\n",
    "        period, std = length, std_dev\n",
    "\n",
    "        # Compute Bollinger Bands\n",
    "        upper_band, middle_band, lower_band = talib.BBANDS(\n",
    "            data['Close'], timeperiod=length, nbdevup=std_dev, nbdevdn=std_dev, matype=0\n",
    "        )\n",
    "\n",
    "        # Current values\n",
    "        last_close = data['Close'].iloc[-1]\n",
    "        lower_band, middle_band, upper_band = lower_band.iloc[-1], middle_band.iloc[-1], upper_band.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if last_close <= lower_band:\n",
    "            bbands_signal = 'Buy'\n",
    "        elif last_close >= upper_band:\n",
    "            bbands_signal = 'Sell'\n",
    "        else:\n",
    "            bbands_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['Bollinger_Bands'],\n",
    "            'signal': [bbands_signal]\n",
    "        })], ignore_index=True)\n",
    "        \n",
    "        self.sma_bands_info = pd.concat([self.sma_bands_info, pd.DataFrame({\n",
    "            'function': ['Bollinger_Bands'],\n",
    "            'signal': [bbands_signal],\n",
    "            'period': [period],\n",
    "            'std': [std],\n",
    "            'lower_band': [lower_band],\n",
    "            'middle_band': [middle_band],\n",
    "            'upper_band': [upper_band]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "\n",
    "    def get_rsi(self, data: pd.DataFrame, length: int = 25, overbought: int = 70, oversold: int = 30):\n",
    "        \"\"\"\n",
    "        This function calculates the RSI and generates a signal based on overbought/oversold levels.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - length: RSI period.\n",
    "        - overbought: RSI overbought threshold.\n",
    "        - oversold: RSI oversold threshold.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.rsi_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "\n",
    "        period, upper_level, lower_level = length, overbought, oversold \n",
    "\n",
    "        # Compute RSI\n",
    "        rsi = talib.RSI(data['Close'], timeperiod=length)\n",
    "        rsi_now = rsi.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if rsi_now >= overbought:\n",
    "            rsi_signal = 'Sell'\n",
    "        elif rsi_now <= oversold:\n",
    "            rsi_signal = 'Buy'\n",
    "        else:\n",
    "            rsi_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['RSI'],\n",
    "            'signal': [rsi_signal]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        self.rsi_info = pd.concat([self.rsi_info, pd.DataFrame({\n",
    "            'function': ['RSI'],\n",
    "            'signal': [rsi_signal],\n",
    "            'period': [period],\n",
    "            'upper_level': [upper_level],\n",
    "            'lower_level': [lower_level]\n",
    "        })], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n",
    "\n",
    "\n",
    "class DataHistory():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self\n",
    "    \n",
    "    def get_yahoo_data_history(self, symbol : str, period : str, interval : str, start = '1900-01-01', end = datetime.now(), prepost : bool = True):\n",
    "        '''\n",
    "        Data collection from yahoo\n",
    "\n",
    "        Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime, inclusive. Default is 1900-01-01 E.g. for start=\"2020-01-01\", the first data point will be on \"2020-01-01\"\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime, exclusive. Default is now E.g. for end=\"2023-01-01\", the last data point will be on \"2022-12-31\"\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results? Default is False\n",
    "        '''\n",
    "        yahoo_data_history = yf.Ticker(symbol).history(period=period, interval=interval, start=start, end=end, prepost=prepost)\n",
    "        return yahoo_data_history\n",
    "    \n",
    "    def get_yahoo_symbol_info(self, symbol : str):\n",
    "        '''\n",
    "        Return detailed information about asset\n",
    "        '''\n",
    "        yahoo_symbol_info = yf.Ticker(symbol).info\n",
    "        return yahoo_symbol_info\n",
    "    \n",
    "    def get_yahoo_symbol_dividends(self, symbol : str):\n",
    "        '''\n",
    "        Return dividents historics\n",
    "        '''\n",
    "        yahoo_symbol_dividends = yf.Ticker(symbol).dividends\n",
    "        return yahoo_symbol_dividends\n",
    "    \n",
    "    def get_yahoo_symbol_splits(self, symbol : str):\n",
    "        '''\n",
    "        Return actions splits historics\n",
    "        '''\n",
    "        yahoo_symbol_splits = yf.Ticker(symbol).splits\n",
    "        return yahoo_symbol_splits\n",
    " \n",
    "    def get_yahoo_symbol_recommendations(self, symbol : str):\n",
    "        '''\n",
    "        Return recommendations about asset\n",
    "        '''\n",
    "        yahoo_symbol_recommendations = yf.Ticker(symbol).recommendations\n",
    "        return yahoo_symbol_recommendations\n",
    "\n",
    "    def get_yahoo_symbol_calendar(self, symbol : str):\n",
    "        '''\n",
    "        Return corporative calendar events about asset\n",
    "        '''\n",
    "        yahoo_symbol_calendar = yf.Ticker(symbol).calendar\n",
    "        return yahoo_symbol_calendar\n",
    "\n",
    "    def get_yahoo_symbol_major_holders(self, symbol : str):\n",
    "        '''\n",
    "        Return the list of major holders\n",
    "        '''\n",
    "        yahoo_symbol_major_holders = yf.Ticker(symbol).major_holders\n",
    "        return yahoo_symbol_major_holders\n",
    "\n",
    "    def get_yahoo_symbol_institutional_holders(self, symbol : str):\n",
    "        '''\n",
    "        Return the list of major institutional holders\n",
    "        '''\n",
    "        yahoo_symbol_institutional_holders = yf.Ticker(symbol).institutional_holders\n",
    "        return yahoo_symbol_institutional_holders\n",
    "\n",
    "    def get_yahoo_symbol_balance_sheet(self, symbol : str):\n",
    "        '''\n",
    "        Return the patrimonial balance sheet\n",
    "        '''\n",
    "        yahoo_symbol_balance_sheet = yf.Ticker(symbol).balance_sheet\n",
    "        return yahoo_symbol_balance_sheet\n",
    "\n",
    "    def get_yahoo_symbol_financials(self, symbol : str):\n",
    "        '''\n",
    "        !!! Not Working !!!\n",
    "        Return the financials results (profits and expenses)\n",
    "        '''\n",
    "        yahoo_symbol_financials = yf.Ticker(symbol).financials\n",
    "        return yahoo_symbol_financials\n",
    "\n",
    "    def get_yahoo_symbol_cashflow(self, symbol : str):\n",
    "        '''\n",
    "        Return the cashflow results\n",
    "        '''\n",
    "        yahoo_symbol_cashflow = yf.Ticker(symbol).cashflow\n",
    "        return yahoo_symbol_cashflow\n",
    "\n",
    "    def get_yahoo_symbol_sustainability(self, symbol : str):\n",
    "        '''\n",
    "        \n",
    "        Return the ESG metrics (enviormental, social and governamental)\n",
    "        '''\n",
    "        yahoo_symbol_sustainability = yf.Ticker(symbol).sustainability\n",
    "        return yahoo_symbol_sustainability\n",
    "\n",
    "    def get_yahoo_symbol_news(self, symbol : str):\n",
    "        '''\n",
    "        Return the latest news about asset\n",
    "        '''\n",
    "        yahoo_symbol_news = yf.Ticker(symbol).news\n",
    "        return yahoo_symbol_news\n",
    "\n",
    "    def get_yahoo_symbol_fast_info(self, symbol : str):\n",
    "        '''\n",
    "        Return the fast information about asset\n",
    "\n",
    "        Data:\n",
    "        exchange : str\n",
    "            Exchange on which the asset is traded\n",
    "        marketCap : float\n",
    "            Marker Cap of asset\n",
    "        quoteType: str\n",
    "            Asset type (EQUITY, CRYPTO, FOREX..)\n",
    "        shares : int\n",
    "            Total Number of shares in circulation            \n",
    "        '''\n",
    "        yahoo_symbol_fast_info_exchange = yf.Ticker(symbol).fast_info.exchange\n",
    "        yahoo_symbol_fast_info_marketcap = yf.Ticker(symbol).fast_info.market_cap\n",
    "        yahoo_symbol_fast_info_quotetype = yf.Ticker(symbol).fast_info.quote_type\n",
    "        yahoo_symbol_fast_info_shares = yf.Ticker(symbol).fast_info.shares\n",
    "        return yahoo_symbol_fast_info_exchange, yahoo_symbol_fast_info_marketcap, yahoo_symbol_fast_info_quotetype, yahoo_symbol_fast_info_shares\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Results df -------------\n",
      "\n",
      "           function signal\n",
      "0        Crossover    Buy\n",
      "1  Bollinger_Bands    Buy\n",
      "2              RSI   Flat \n",
      "\n",
      "------------- \n",
      "------------- Results Crossover -------------\n",
      "\n",
      "     function signal period_low period_mid period_high ema_low ema_mid  \\\n",
      "0  Crossover    Buy         25         50         200     NaN     NaN   \n",
      "\n",
      "  ema_high    ema1_now    ema2_now    ema3_now  \n",
      "0      NaN  432.187188  430.023366  417.012547   \n",
      "\n",
      "------------- \n",
      "------------- Results Bollinger Bands -------------\n",
      "\n",
      "           function signal period std  lower_band  middle_band  upper_band\n",
      "0  Bollinger_Bands    Buy     15   1  425.586317   436.358663  447.131009 \n",
      "\n",
      "------------- \n",
      "------------- Results RSI -------------\n",
      "\n",
      "   function signal period upper_level lower_level\n",
      "0      RSI   Flat     25          70          30 \n",
      "\n",
      "------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_8728\\1517949193.py:100: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.sma_bands_info = pd.concat([self.sma_bands_info, pd.DataFrame({\n"
     ]
    }
   ],
   "source": [
    "dh = DataHistory()\n",
    "df = dh.get_yahoo_data_history('MSFT', '1y', '1d')\n",
    "\n",
    "tm = TrendMetrics()\n",
    "tm.get_crossover(data=df, l1=25, l2=50, l3=200 )\n",
    "tm.get_sma_bands(data=df, length=15, std_dev=1)\n",
    "tm.get_rsi(data=df, length=25, overbought=70, oversold=30)\n",
    "\n",
    "print('------------- Results df -------------\\n\\n',tm.result_df,'\\n\\n------------- ')\n",
    "\n",
    "print('------------- Results Crossover -------------\\n\\n',tm.crossover_info,'\\n\\n------------- ')\n",
    "\n",
    "print('------------- Results Bollinger Bands -------------\\n\\n',tm.sma_bands_info,'\\n\\n------------- ')\n",
    "\n",
    "print('------------- Results RSI -------------\\n\\n',tm.rsi_info,'\\n\\n------------- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6.QtCore import Qt\n",
    "from PySide6.QtGui import QColor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
