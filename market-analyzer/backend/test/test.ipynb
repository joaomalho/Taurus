{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Fundamental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_yahoo_economic_calendar(table_class: str = None) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Extrat data from trading economics callendar.\n",
    "\n",
    "#     Parameters:\n",
    "#         classe_tabela (str): Class CSS from table to scrap (optional).\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame with table content.\n",
    "#     \"\"\"\n",
    "\n",
    "#     headers = {\n",
    "#         \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "#     }\n",
    "\n",
    "#     try:\n",
    "#         response = requests.get(\"https://tradingeconomics.com/calendar\", headers=headers)\n",
    "#         response.raise_for_status()\n",
    "\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#         if table_class:\n",
    "#             tabela = soup.find('table', {'class': table_class})\n",
    "#         else:\n",
    "#             tabela = soup.find('table')\n",
    "        \n",
    "#         headers = [th.text.strip() for th in tabela.find_all('th')]\n",
    "#         print(headers)\n",
    "#         rows = []\n",
    "#         for row in tabela.find_all('tr')[1:]:\n",
    "#             cols = [td.text.strip() for td in row.find_all('td')]\n",
    "#             if cols: \n",
    "#                 rows.append(cols)\n",
    "\n",
    "#         df = pd.DataFrame(rows, columns=headers if headers else None)\n",
    "        \n",
    "\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Error accessing URL: {e}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing data: {e}\")\n",
    "\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_whalewisdom(ticker: str) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Extracts data from WhaleWisdom for a given stock ticker.\n",
    "\n",
    "#     Parameters:\n",
    "#         ticker (str): Stock ticker symbol.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame with table content.\n",
    "#     \"\"\"\n",
    "\n",
    "#     headers = {\n",
    "#         \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "#     }\n",
    "\n",
    "#     try:\n",
    "#         response = requests.get(f\"https://whalewisdom.com/stock/{ticker}\", headers=headers)\n",
    "#         response.raise_for_status()\n",
    "\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "#         # Encontrar a div com a classe \"v-data-table__wrapper\"\n",
    "#         div_wrapper = soup.find('div', {'class': 'v-window__container'})\n",
    "       \n",
    "#         if not div_wrapper:\n",
    "#             raise ValueError(\"Div com a classe 'v-window__container' não encontrada.\")\n",
    "\n",
    "#         # Buscar a primeira tabela dentro desta div\n",
    "#         tabela = div_wrapper.find('table')\n",
    "#         if not tabela:\n",
    "#             raise ValueError(\"Nenhuma tabela encontrada dentro da div especificada.\")\n",
    "        \n",
    "#         # Coletar os cabeçalhos da tabela ignorando ícones\n",
    "#         headers = [th.find('span').text.strip() for th in tabela.find_all('th') if th.find('span')]\n",
    "#         # print(headers)\n",
    "\n",
    "#         # Encontrando todas as linhas dentro da tabela (tbody > tr)\n",
    "#         rows = tabela.find(\"tbody\").find_all(\"tr\")\n",
    "#         print(rows)\n",
    "#         # Extraindo os dados de cada linha\n",
    "#         data = []\n",
    "#         for row in rows:\n",
    "#             columns = row.find_all(\"td\")\n",
    "\n",
    "#             # Pegando os valores correspondentes\n",
    "#             institution_name = columns[0].text.strip()\n",
    "#             shares_held = columns[2].text.strip()\n",
    "#             portfolio_value = columns[3].text.strip()\n",
    "#             percentage_ownership = columns[4].text.strip()\n",
    "#             last_report_date = columns[-1].text.strip()\n",
    "\n",
    "#             data.append({\n",
    "#                 \"Instituição\": institution_name,\n",
    "#                 \"Ações Detidas\": shares_held,\n",
    "#                 \"Valor do Portfólio\": portfolio_value,\n",
    "#                 \"Percentual de Participação\": percentage_ownership,\n",
    "#                 \"Última Atualização\": last_report_date\n",
    "#             })\n",
    "#         #print(data)\n",
    "    \n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Erro ao acessar a URL: {e}\")\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Erro na extração de dados: {e}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro inesperado: {e}\")\n",
    "    \n",
    "#     return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_whale_s = get_whalewisdom(ticker = \"ctre\")\n",
    "# df_whale_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = 'https://whalewisdom.com/shell/command.html?args=%7B%22command%22:%22filer_lookup%22,%20%22name%22:%22berkshire%22%7D'\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "#     \"Accept\": \"application/json\"\n",
    "# }\n",
    "\n",
    "# response = requests.get(base_url, headers=headers)\n",
    "# response.raise_for_status()\n",
    "\n",
    "# response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hashlib\n",
    "# import hmac\n",
    "# import base64\n",
    "# import json\n",
    "# import time\n",
    "# import urllib.parse\n",
    "# import requests\n",
    "\n",
    "# class WhaleWisdom:\n",
    "#     def __init__(self, secret_key, shared_key):\n",
    "#         self.secret_key = secret_key\n",
    "#         self.shared_key = shared_key\n",
    "#         self.timestamp = self.get_timestamp()\n",
    "\n",
    "#     def get_timestamp(self):\n",
    "#         \"\"\"Gera o timestamp no formato UTC\"\"\"\n",
    "#         return time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())\n",
    "\n",
    "#     def signature(self, args):\n",
    "#         \"\"\"Gera a assinatura HMAC-SHA1 em Base64\"\"\"\n",
    "#         message = f\"{args}\\n{self.timestamp}\".encode('utf-8')\n",
    "#         hmac_digest = hmac.new(self.secret_key.encode('utf-8'), message, hashlib.sha1).digest()\n",
    "#         return base64.b64encode(hmac_digest).decode('utf-8')\n",
    "\n",
    "#     def encode(self, string):\n",
    "#         \"\"\"Codifica a string para URL\"\"\"\n",
    "#         return urllib.parse.quote(string, safe='')\n",
    "\n",
    "#     def endpoint(self, args):\n",
    "#         \"\"\"Constrói a URL da API do WhaleWisdom\"\"\"\n",
    "#         encoded_args = self.encode(json.dumps(args))\n",
    "#         api_sig = self.signature(json.dumps(args))\n",
    "#         encoded_timestamp = self.encode(self.timestamp)\n",
    "\n",
    "#         return f\"https://whalewisdom.com/shell/command.json?args={encoded_args}&api_shared_key={self.shared_key}&api_sig={api_sig}&timestamp={encoded_timestamp}\"\n",
    "\n",
    "#     def request(self, args):\n",
    "#         \"\"\"Faz a requisição à API\"\"\"\n",
    "#         url = self.endpoint(args)\n",
    "#         response = requests.get(url)\n",
    "\n",
    "#         if response.status_code == 200:\n",
    "#             return response.text\n",
    "#         else:\n",
    "#             print(f\"Erro {response.status_code}: {response.text}\")\n",
    "#             return None\n",
    "\n",
    "\n",
    "# # **Exemplo de Uso**\n",
    "# WW_SHARED_KEY = \"aTWxWrcILEOGqkAPZtAL\"\n",
    "# WW_SECRET_KEY = \"JGlAleUrGy1bWaLoiWwESNIbTHaovA0ocKOnr4MW\"\n",
    "\n",
    "# ww = WhaleWisdom(secret_key=WW_SECRET_KEY, shared_key=WW_SHARED_KEY)\n",
    "\n",
    "# # Obter as participações (holdings) de um gestor específico\n",
    "# response = ww.request({\n",
    "#     \"command\": \"stock_lookup\",\n",
    "#     \"symbol\": \"ctre\"\n",
    "# })\n",
    "\n",
    "# data = json.loads(response)\n",
    "\n",
    "# stock_id = data[\"stocks\"][0][\"id\"]\n",
    "# name = data[\"stocks\"][0][\"name\"]\n",
    "# status = data[\"stocks\"][0][\"status\"]\n",
    "# link = data[\"stocks\"][0][\"link\"]\n",
    "\n",
    "# stock_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = ww.request(\n",
    "# {\"command\":\"holdings\",\"stock_ids\":[167941],\"filer_ids\":[373], \"limit\": 10, \"all_quarters\":0})\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCKS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.signal import argrelextrema\n",
    "# import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from django.core.validators import RegexValidator\n",
    "from django.http import JsonResponse, Http404\n",
    "\n",
    "# S&P 500 → ^GSPC\n",
    "# Dow Jones → ^DJI\n",
    "# Nasdaq 100 → ^NDX\n",
    "# Russell 2000 → ^RUT\n",
    "# DAX (Alemanha) → ^GDAXI\n",
    "# Definir o ticker da ação\n",
    "symbol = \"AAPL\"  # Apple Inc.\n",
    "# symbol = \"^GSPC\"  # Apple Inc.\n",
    "# symbol = \"XLK\"  # Apple Inc.\n",
    "\n",
    "# Definir período e intervalo\n",
    "period = \"1y\"       # Período de 1 mês\n",
    "interval = \"1d\"      # Dados diários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_symbol(symbol):\n",
    "    \"\"\"\n",
    "    Valida se o símbolo é uma string alfanumérica com no máximo 10 caracteres.\n",
    "    \"\"\"\n",
    "    validator = RegexValidator(regex=r'^[A-Z0-9.]{1,10}$', message=\"Invalid symbol format.\")\n",
    "    try:\n",
    "        validator(symbol)\n",
    "        return symbol\n",
    "    except Exception:\n",
    "        raise Http404(\"Invalid stock symbol.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_history_1( symbol : str, period : str, interval : str, start = '1900-01-01', end = datetime.now(), prepost : bool = True):\n",
    "        '''\n",
    "        Data collection from yahoo\n",
    "\n",
    "        Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime, inclusive. Default is 1900-01-01 E.g. for start=\"2020-01-01\", the first data point will be on \"2020-01-01\"\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime, exclusive. Default is now E.g. for end=\"2023-01-01\", the last data point will be on \"2022-12-31\"\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results? Default is False\n",
    "        '''\n",
    "        yahoo_data_history = yf.Ticker(symbol).history(period=period, interval=interval, start=start, end=end, prepost=prepost)\n",
    "        yahoo_data_history.reset_index(inplace=True)\n",
    "\n",
    "        yahoo_data_history[\"Date\"] = yahoo_data_history[\"Date\"].dt.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "        return yahoo_data_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_data_history = yf.Ticker(symbol).history(period=\"1mo\", interval=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_history(request, symbol):\n",
    "        '''\n",
    "        Data collection from yahoo\n",
    "\n",
    "        Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime, inclusive. Default is 1900-01-01 E.g. for start=\"2020-01-01\", the first data point will be on \"2020-01-01\"\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime, exclusive. Default is now E.g. for end=\"2023-01-01\", the last data point will be on \"2022-12-31\"\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results? Default is False\n",
    "        '''\n",
    "        try:\n",
    "            symbol = symbol.strip().upper()\n",
    "            \n",
    "            if not symbol:\n",
    "                return JsonResponse({\"error\": \"Symbol is missing\"}, status=400)\n",
    "\n",
    "            symbol = validate_symbol(symbol)\n",
    "        \n",
    "            per = request.GET.get(\"period\", \"1mo\")\n",
    "            interval_time = request.GET.get(\"interval\", \"1d\")\n",
    "\n",
    "            try:\n",
    "                df = get_data_history_1(symbol=symbol, period=per, interval=interval_time)\n",
    "                \n",
    "                if df is None or df.empty:\n",
    "                    return JsonResponse({\"error\": \"No data found\"}, status=404)\n",
    "\n",
    "                return JsonResponse({\"data\": df.to_dict(orient=\"records\")})\n",
    "\n",
    "            except Exception as e:\n",
    "                return JsonResponse({\"error\": str(e)}, status=500)\n",
    "        except Exception as e:\n",
    "            return JsonResponse({\"error\": f\"Unexpected server error: {str(e)}\"}, status=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting period, start and end is nonsense. Set maximum 2 of them.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m a = \u001b[43mget_data_history_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAAPL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1y\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1d\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(a.head())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mget_data_history_1\u001b[39m\u001b[34m(symbol, period, interval, start, end, prepost)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_data_history_1\u001b[39m( symbol : \u001b[38;5;28mstr\u001b[39m, period : \u001b[38;5;28mstr\u001b[39m, interval : \u001b[38;5;28mstr\u001b[39m, start = \u001b[33m'\u001b[39m\u001b[33m1900-01-01\u001b[39m\u001b[33m'\u001b[39m, end = datetime.now(), prepost : \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m        Data collection from yahoo\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m            Include Pre and Post market data in results? Default is False\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m        '''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m         yahoo_data_history = \u001b[43myf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTicker\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m         yahoo_data_history.reset_index(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     20\u001b[39m         yahoo_data_history[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m] = yahoo_data_history[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m].dt.strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Taurus Python\\taurus-311\\Lib\\site-packages\\yfinance\\utils.py:92\u001b[39m, in \u001b[36mlog_indent_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Taurus Python\\taurus-311\\Lib\\site-packages\\yfinance\\base.py:101\u001b[39m, in \u001b[36mTickerBase.history\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;129m@utils\u001b[39m.log_indent_decorator\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhistory\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs) -> pd.DataFrame:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lazy_load_price_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Taurus Python\\taurus-311\\Lib\\site-packages\\yfinance\\utils.py:92\u001b[39m, in \u001b[36mlog_indent_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Taurus Python\\taurus-311\\Lib\\site-packages\\yfinance\\scrapers\\history.py:164\u001b[39m, in \u001b[36mPriceHistory.history\u001b[39m\u001b[34m(self, period, interval, start, end, prepost, actions, auto_adjust, back_adjust, repair, keepna, proxy, rounding, timeout, raise_errors)\u001b[39m\n\u001b[32m    162\u001b[39m         start += \u001b[32m5\u001b[39m \u001b[38;5;66;03m# allow for processing time\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m start \u001b[38;5;129;01mand\u001b[39;00m end:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSetting period, start and end is nonsense. Set maximum 2 of them.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m start \u001b[38;5;129;01mor\u001b[39;00m end:\n\u001b[32m    166\u001b[39m     period_td = utils._interval_to_timedelta(period)\n",
      "\u001b[31mValueError\u001b[39m: Setting period, start and end is nonsense. Set maximum 2 of them."
     ]
    }
   ],
   "source": [
    "a = get_data_history_1(symbol=\"AAPL\", period=\"1y\", interval=\"1d\")\n",
    "print(a.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taurus-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
