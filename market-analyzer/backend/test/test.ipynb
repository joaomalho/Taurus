{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_data_history(symbol : str, period : str, interval: str, start = '1900-01-01', end = datetime.now(), prepost : bool = True):\n",
    "        '''\n",
    "        Data collection from yahoo\n",
    "\n",
    "        Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime, inclusive. Default is 1900-01-01 E.g. for start=\"2020-01-01\", the first data point will be on \"2020-01-01\"\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime, exclusive. Default is now E.g. for end=\"2023-01-01\", the last data point will be on \"2022-12-31\"\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results? Default is False\n",
    "        debug: bool\n",
    "            If passed as False, will suppress error message printing to console.\n",
    "        '''\n",
    "        yahoo_data_history = yf.Ticker(symbol).history(period=period, interval=interval, start=start, end=end, prepost=prepost)\n",
    "        return yahoo_data_history\n",
    "\n",
    "history = get_yahoo_data_history(symbol=\"MSFT\",period='1y', interval='1d', end = datetime.now(), prepost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986-03-13 00:00:00-05:00</th>\n",
       "      <td>0.054485</td>\n",
       "      <td>0.062498</td>\n",
       "      <td>0.054485</td>\n",
       "      <td>0.059827</td>\n",
       "      <td>1031788800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-14 00:00:00-05:00</th>\n",
       "      <td>0.059827</td>\n",
       "      <td>0.063032</td>\n",
       "      <td>0.059827</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>308160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-17 00:00:00-05:00</th>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.063566</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.063032</td>\n",
       "      <td>133171200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-18 00:00:00-05:00</th>\n",
       "      <td>0.063032</td>\n",
       "      <td>0.063566</td>\n",
       "      <td>0.060895</td>\n",
       "      <td>0.061429</td>\n",
       "      <td>67766400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-19 00:00:00-05:00</th>\n",
       "      <td>0.061429</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.059827</td>\n",
       "      <td>0.060361</td>\n",
       "      <td>47894400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 00:00:00-05:00</th>\n",
       "      <td>411.600006</td>\n",
       "      <td>415.410004</td>\n",
       "      <td>408.660004</td>\n",
       "      <td>410.920013</td>\n",
       "      <td>25679100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-04 00:00:00-05:00</th>\n",
       "      <td>412.690002</td>\n",
       "      <td>413.920013</td>\n",
       "      <td>409.739990</td>\n",
       "      <td>412.369995</td>\n",
       "      <td>20532100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-05 00:00:00-05:00</th>\n",
       "      <td>412.350006</td>\n",
       "      <td>413.829987</td>\n",
       "      <td>410.399994</td>\n",
       "      <td>413.290009</td>\n",
       "      <td>16316700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-06 00:00:00-05:00</th>\n",
       "      <td>414.000000</td>\n",
       "      <td>418.200012</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>415.820007</td>\n",
       "      <td>16309800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-07 00:00:00-05:00</th>\n",
       "      <td>416.480011</td>\n",
       "      <td>418.649994</td>\n",
       "      <td>408.100006</td>\n",
       "      <td>409.750000</td>\n",
       "      <td>22860700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9804 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "1986-03-13 00:00:00-05:00    0.054485    0.062498    0.054485    0.059827   \n",
       "1986-03-14 00:00:00-05:00    0.059827    0.063032    0.059827    0.061963   \n",
       "1986-03-17 00:00:00-05:00    0.061963    0.063566    0.061963    0.063032   \n",
       "1986-03-18 00:00:00-05:00    0.063032    0.063566    0.060895    0.061429   \n",
       "1986-03-19 00:00:00-05:00    0.061429    0.061963    0.059827    0.060361   \n",
       "...                               ...         ...         ...         ...   \n",
       "2025-02-03 00:00:00-05:00  411.600006  415.410004  408.660004  410.920013   \n",
       "2025-02-04 00:00:00-05:00  412.690002  413.920013  409.739990  412.369995   \n",
       "2025-02-05 00:00:00-05:00  412.350006  413.829987  410.399994  413.290009   \n",
       "2025-02-06 00:00:00-05:00  414.000000  418.200012  414.000000  415.820007   \n",
       "2025-02-07 00:00:00-05:00  416.480011  418.649994  408.100006  409.750000   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits  \n",
       "Date                                                            \n",
       "1986-03-13 00:00:00-05:00  1031788800        0.0           0.0  \n",
       "1986-03-14 00:00:00-05:00   308160000        0.0           0.0  \n",
       "1986-03-17 00:00:00-05:00   133171200        0.0           0.0  \n",
       "1986-03-18 00:00:00-05:00    67766400        0.0           0.0  \n",
       "1986-03-19 00:00:00-05:00    47894400        0.0           0.0  \n",
       "...                               ...        ...           ...  \n",
       "2025-02-03 00:00:00-05:00    25679100        0.0           0.0  \n",
       "2025-02-04 00:00:00-05:00    20532100        0.0           0.0  \n",
       "2025-02-05 00:00:00-05:00    16316700        0.0           0.0  \n",
       "2025-02-06 00:00:00-05:00    16309800        0.0           0.0  \n",
       "2025-02-07 00:00:00-05:00    22860700        0.0           0.0  \n",
       "\n",
       "[9804 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "\n",
    "class CandlesPatterns:\n",
    "    \"\"\"\n",
    "    Detect all candlestick patterns using TA-Lib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.result_candles_history_df = pd.DataFrame(columns=['Pattern', 'Signal', 'Relevance', 'Stoploss'])\n",
    "        self.result_candles_df = pd.DataFrame(columns=['Pattern', 'Signal', 'Relevance', 'Stoploss'])\n",
    "        \n",
    "        \n",
    "    def detect_pattern(self, data: pd.DataFrame, pattern_function, pattern_name: str):\n",
    "        \"\"\"\n",
    "        General method to detect a specific candlestick pattern.\n",
    "        \"\"\"\n",
    "        data_pass = data\n",
    "\n",
    "        detection = pattern_function(data_pass['Open'], data_pass['High'], data_pass['Low'], data_pass['Close'])\n",
    "\n",
    "        non_zero_detection = detection[detection != 0]\n",
    "        if not non_zero_detection.empty:\n",
    "            for date, signal in non_zero_detection.items():\n",
    "                # Cálculo do Stoploss baseado no padrão\n",
    "                if pattern_name in [\n",
    "                    \"doji\", \"dragonfly_doji\", \"gravestone_doji\", \"engulfing\",\n",
    "                    \"morning_star\", \"evening_star\", \"marubozu\", \"harami\",\n",
    "                    \"harami_cross\", \"kicking\", \"kicking_by_length\", \"tasuki_gap\",\n",
    "                    \"gap_side_by_side_white\", \"counter_attack\", \"piercing\",\n",
    "                    \"dark_cloud_cover\", \"tri_star\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'Low'],5) if signal > 0 else round(data_pass.loc[date, 'High'],5)\n",
    "                elif pattern_name in [\n",
    "                    \"morning_doji_star\", \"hammer\", \"inverted_hammer\",\n",
    "                    \"thrusting\", \"matching_low\", \"three_white_soldiers\",\n",
    "                    \"three_outside\", \"three_stars_in_south\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'Low'],5)\n",
    "                elif pattern_name in [\n",
    "                    \"evening_doji_star\", \"hanging_man\", \"shooting_star\",\n",
    "                    \"on_neck\", \"in_neck\", \"three_black_crows\",\n",
    "                    \"three_inside\", \"advance_block\", \"stalled_pattern\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'High'],5)\n",
    "                else:\n",
    "                    stoploss = None\n",
    "\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'Pattern': [pattern_name],\n",
    "                    'Signal': [signal],\n",
    "                    'Relevance': ['Flat'],\n",
    "                    'Stoploss': [stoploss],\n",
    "                }, index=[date])\n",
    "\n",
    "                self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
    "\n",
    "                self.result_candles_df = self.result_candles_df[self.result_candles_df['Pattern'] != pattern_name]\n",
    "                self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n",
    "\n",
    "        return detection\n",
    "\n",
    "    def doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDOJI, \"doji\")\n",
    "\n",
    "    def dragonfly_doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDRAGONFLYDOJI, \"dragonfly_doji\")\n",
    "\n",
    "    def gravestone_doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLGRAVESTONEDOJI, \"gravestone_doji\")\n",
    "\n",
    "    def engulfing(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLENGULFING, \"engulfing\")\n",
    "\n",
    "    def morning_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLMORNINGSTAR, \"morning_star\")\n",
    "\n",
    "    def evening_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLEVENINGSTAR, \"evening_star\")\n",
    "\n",
    "    def morning_doji_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMORNINGDOJISTAR, \"morning_doji_star\")\n",
    "\n",
    "    def evening_doji_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLEVENINGDOJISTAR, \"evening_doji_star\")\n",
    "\n",
    "    def hammer(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLHAMMER, \"hammer\")\n",
    "\n",
    "    def inverted_hammer(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLINVERTEDHAMMER, \"inverted_hammer\")\n",
    "\n",
    "    def hanging_man(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLHANGINGMAN, \"hanging_man\")\n",
    "\n",
    "    def shooting_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLSHOOTINGSTAR, \"shooting_star\")\n",
    "\n",
    "    def marubozu(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMARUBOZU, \"marubozu\")\n",
    "\n",
    "    def harami(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLHARAMI, \"harami\")\n",
    "\n",
    "    def harami_cross(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLHARAMICROSS, \"harami_cross\")\n",
    "\n",
    "    def spinning_top(self, data: pd.DataFrame):\n",
    "        '''\n",
    "        NEED FIBONACCI\n",
    "        '''\n",
    "        return self.detect_pattern(data, talib.CDLSPINNINGTOP, \"spinning_top\")\n",
    "\n",
    "    def kicking(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLKICKING, \"kicking\")\n",
    "\n",
    "    def kicking_by_length(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLKICKINGBYLENGTH, \"kicking_by_length\")\n",
    "\n",
    "    def tasuki_gap(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTASUKIGAP, \"tasuki_gap\")\n",
    "\n",
    "    def gap_side_by_side_white(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLGAPSIDESIDEWHITE, \"gap_side_by_side_white\")\n",
    "\n",
    "    def counter_attack(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLCOUNTERATTACK, \"counter_attack\")\n",
    "\n",
    "    def piercing(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLPIERCING, \"piercing\")\n",
    "\n",
    "    def dark_cloud_cover(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDARKCLOUDCOVER, \"dark_cloud_cover\")\n",
    "\n",
    "    def tri_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTRISTAR, \"tri_star\")\n",
    "\n",
    "    def on_neck(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLONNECK, \"on_neck\")\n",
    "\n",
    "    def in_neck(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLINNECK, \"in_neck\")\n",
    "\n",
    "    def thrusting(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTHRUSTING, \"thrusting\")\n",
    "\n",
    "    def matching_low(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMATCHINGLOW, \"matching_low\")\n",
    "\n",
    "    def three_black_crows(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3BLACKCROWS, \"three_black_crows\")\n",
    "\n",
    "    def three_white_soldiers(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3WHITESOLDIERS, \"three_white_soldiers\")\n",
    "\n",
    "    def three_inside(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3INSIDE, \"three_inside\")\n",
    "\n",
    "    def three_outside(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3OUTSIDE, \"three_outside\")\n",
    "\n",
    "    def three_stars_in_south(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3STARSINSOUTH, \"three_stars_in_south\")\n",
    "\n",
    "    def advance_block(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLADVANCEBLOCK, \"advance_block\")\n",
    "\n",
    "    def stalled_pattern(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLSTALLEDPATTERN, \"stalled_pattern\")\n",
    "\n",
    "    # def abandoned_baby(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLABANDONEDBABY, \"abandoned_baby\")\n",
    "\n",
    "    # def unique_3_river(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLUNIQUE3RIVER, \"unique_3_river\")\n",
    "\n",
    "    # def belt_hold(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLBELTHOLD, \"belt_hold\")\n",
    "\n",
    "    # def separating_lines(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLSEPARATINGLINES, \"Separating Lines\")\n",
    "\n",
    "    # def upside_gap_two_crows(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLUPSIDEGAP2CROWS, \"Upside Gap Two Crows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_30644\\45596638.py:56: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_30644\\45596638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_30644\\45596638.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_30644\\45596638.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Detected Patterns with Stoploss:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Stoploss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-18 00:00:00-04:00</th>\n",
       "      <td>advance_block</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>543.35483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-18 00:00:00-04:00</th>\n",
       "      <td>counter_attack</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>424.30300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-22 00:00:00-04:00</th>\n",
       "      <td>dark_cloud_cover</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>385.83253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>dragonfly_doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-02 00:00:00-04:00</th>\n",
       "      <td>engulfing</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>540.16957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-20 00:00:00-04:00</th>\n",
       "      <td>evening_doji_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>445.94879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26 00:00:00-05:00</th>\n",
       "      <td>evening_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>502.30675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24 00:00:00-05:00</th>\n",
       "      <td>gap_side_by_side_white</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>447.15796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28 00:00:00-04:00</th>\n",
       "      <td>gravestone_doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>517.76279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-17 00:00:00-04:00</th>\n",
       "      <td>hammer</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>522.25927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-06 00:00:00-04:00</th>\n",
       "      <td>hanging_man</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>530.28146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>harami</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>harami_cross</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-18 00:00:00-04:00</th>\n",
       "      <td>in_neck</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>428.77130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-24 00:00:00-04:00</th>\n",
       "      <td>inverted_hammer</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.14609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-03 00:00:00-04:00</th>\n",
       "      <td>marubozu</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.13762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13 00:00:00-04:00</th>\n",
       "      <td>matching_low</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>514.75195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-22 00:00:00-04:00</th>\n",
       "      <td>morning_doji_star</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>369.50896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12 00:00:00-04:00</th>\n",
       "      <td>morning_star</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>504.39004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-11 00:00:00-04:00</th>\n",
       "      <td>on_neck</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>505.39713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-25 00:00:00-04:00</th>\n",
       "      <td>piercing</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>421.58106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-18 00:00:00-04:00</th>\n",
       "      <td>shooting_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>510.53284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-21 00:00:00-04:00</th>\n",
       "      <td>spinning_top</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01 00:00:00-05:00</th>\n",
       "      <td>stalled_pattern</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>434.13640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 00:00:00-05:00</th>\n",
       "      <td>tasuki_gap</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>382.23816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-02 00:00:00-04:00</th>\n",
       "      <td>three_inside</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.49524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-03 00:00:00-04:00</th>\n",
       "      <td>three_outside</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.13762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-13 00:00:00-05:00</th>\n",
       "      <td>three_white_soldiers</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>456.39164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01 00:00:00-04:00</th>\n",
       "      <td>thrusting</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>376.05610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-27 00:00:00-05:00</th>\n",
       "      <td>tri_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>447.90530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Pattern Signal Relevance   Stoploss\n",
       "2024-06-18 00:00:00-04:00           advance_block   -100      Flat  543.35483\n",
       "2023-08-18 00:00:00-04:00          counter_attack    100      Flat  424.30300\n",
       "2022-07-22 00:00:00-04:00        dark_cloud_cover   -100      Flat  385.83253\n",
       "2024-07-01 00:00:00-04:00                    doji    100      Flat  539.04680\n",
       "2024-07-01 00:00:00-04:00          dragonfly_doji    100      Flat  539.04680\n",
       "2024-07-02 00:00:00-04:00               engulfing    100      Flat  540.16957\n",
       "2023-07-20 00:00:00-04:00       evening_doji_star   -100      Flat  445.94879\n",
       "2024-02-26 00:00:00-05:00            evening_star   -100      Flat  502.30675\n",
       "2023-11-24 00:00:00-05:00  gap_side_by_side_white    100      Flat  447.15796\n",
       "2024-03-28 00:00:00-04:00         gravestone_doji    100      Flat  517.76279\n",
       "2024-05-17 00:00:00-04:00                  hammer    100      Flat  522.25927\n",
       "2024-06-06 00:00:00-04:00             hanging_man   -100      Flat  530.28146\n",
       "2024-07-01 00:00:00-04:00                  harami    100      Flat  539.04680\n",
       "2024-07-01 00:00:00-04:00            harami_cross    100      Flat  539.04680\n",
       "2023-08-18 00:00:00-04:00                 in_neck   -100      Flat  428.77130\n",
       "2024-06-24 00:00:00-04:00         inverted_hammer    100      Flat  539.14609\n",
       "2024-07-03 00:00:00-04:00                marubozu    100      Flat  545.13762\n",
       "2024-05-13 00:00:00-04:00            matching_low    100      Flat  514.75195\n",
       "2021-03-22 00:00:00-04:00       morning_doji_star    100      Flat  369.50896\n",
       "2024-03-12 00:00:00-04:00            morning_star    100      Flat  504.39004\n",
       "2024-03-11 00:00:00-04:00                 on_neck   -100      Flat  505.39713\n",
       "2023-09-25 00:00:00-04:00                piercing    100      Flat  421.58106\n",
       "2024-03-18 00:00:00-04:00           shooting_star   -100      Flat  510.53284\n",
       "2024-06-21 00:00:00-04:00            spinning_top    100      Flat        NaN\n",
       "2022-02-01 00:00:00-05:00         stalled_pattern   -100      Flat  434.13640\n",
       "2022-11-14 00:00:00-05:00              tasuki_gap    100      Flat  382.23816\n",
       "2024-07-02 00:00:00-04:00            three_inside    100      Flat  545.49524\n",
       "2024-07-03 00:00:00-04:00           three_outside    100      Flat  545.13762\n",
       "2023-12-13 00:00:00-05:00    three_white_soldiers    100      Flat  456.39164\n",
       "2022-09-01 00:00:00-04:00               thrusting   -100      Flat  376.05610\n",
       "2023-11-27 00:00:00-05:00                tri_star   -100      Flat  447.90530"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "symbol = 'SPY'\n",
    "start, end = '2015-01-01', '2024-07-05'\n",
    "\n",
    "data = yf.Ticker(symbol).history(period='1y', interval='1d', start=start, end=end)\n",
    "\n",
    "cm = CandlesPatterns()\n",
    "\n",
    "# Loop para detectar padrões\n",
    "for candle_function in dir(cm):\n",
    "    if (not candle_function.startswith(\"__\") and \n",
    "        callable(getattr(cm, candle_function)) and \n",
    "        candle_function != \"detect_pattern\"):\n",
    "        pattern_function = getattr(cm, candle_function)\n",
    "        try:\n",
    "            candle_result = pattern_function(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting pattern {candle_function}: {e}\")\n",
    "\n",
    "# Verificar padrões detectados e valores de stoploss\n",
    "print(\"\\nAll Detected Patterns with Stoploss:\")\n",
    "cm.result_candles_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "\n",
    "class TrendMetrics():\n",
    "    \"\"\"\n",
    "    A class that encapsulates technical analysis metrics using TA-Lib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.result_df = pd.DataFrame(columns=['function', 'signal'])\n",
    "        self.crossover_info = pd.DataFrame(columns=['function', 'signal', 'period_low', 'period_mid', 'period_high', 'ema_low', 'ema_mid', 'ema_high'])\n",
    "        self.sma_bands_info = pd.DataFrame(columns=['function', 'signal', 'period', 'std', 'lower_band', 'middle_band', 'upper_band'])\n",
    "        self.rsi_info = pd.DataFrame(columns=['function', 'signal', 'period', 'upper_level', 'lower_level'])\n",
    "\n",
    "    def get_crossover(self, data: pd.DataFrame, l1: int, l2: int, l3: int):\n",
    "        \"\"\"\n",
    "        This function measures the crossover of 3 EMAs using TA-Lib.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - l1, l2, l3: Periods for the 3 EMAs.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.crossover_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "        period_low, period_mid, period_high = l1, l2, l3\n",
    "        \n",
    "        # Compute EMAs\n",
    "        ema1 = talib.EMA(data['Close'], timeperiod=l1)\n",
    "        ema2 = talib.EMA(data['Close'], timeperiod=l2)\n",
    "        ema3 = talib.EMA(data['Close'], timeperiod=l3)\n",
    "\n",
    "        # Current values\n",
    "        ema_low, ema_mid, ema_high = ema1.iloc[-1], ema2.iloc[-1], ema3.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if ema_low > ema_mid > ema_high:\n",
    "            crossover_signal = 'Buy'\n",
    "        elif ema_low < ema_mid < ema_high:\n",
    "            crossover_signal = 'Sell'\n",
    "        else:\n",
    "            crossover_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['Crossover'],\n",
    "            'signal': [crossover_signal]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        # Save result\n",
    "        self.crossover_info = pd.concat([self.crossover_info, pd.DataFrame({\n",
    "            'function': ['Crossover'],\n",
    "            'signal': [crossover_signal],\n",
    "            'period_low': [period_low],\n",
    "            'period_mid': [period_mid],\n",
    "            'period_high': [period_high],\n",
    "            'ema1_now': [ema_low],\n",
    "            'ema2_now': [ema_mid],\n",
    "            'ema3_now': [ema_high],\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    def get_sma_bands(self, data: pd.DataFrame, length: int=15, std_dev: int = 1):\n",
    "        \"\"\"\n",
    "        This function calculates Bollinger Bands and detects signals based on them.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - length: SMA period.\n",
    "        - std_dev: Number of standard deviations for the bands.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.bbands_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "\n",
    "        period, std = length, std_dev\n",
    "\n",
    "        # Compute Bollinger Bands\n",
    "        upper_band, middle_band, lower_band = talib.BBANDS(\n",
    "            data['Close'], timeperiod=length, nbdevup=std_dev, nbdevdn=std_dev, matype=0\n",
    "        )\n",
    "\n",
    "        # Current values\n",
    "        last_close = data['Close'].iloc[-1]\n",
    "        lower_band, middle_band, upper_band = lower_band.iloc[-1], middle_band.iloc[-1], upper_band.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if last_close <= lower_band:\n",
    "            bbands_signal = 'Buy'\n",
    "        elif last_close >= upper_band:\n",
    "            bbands_signal = 'Sell'\n",
    "        else:\n",
    "            bbands_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['Bollinger_Bands'],\n",
    "            'signal': [bbands_signal]\n",
    "        })], ignore_index=True)\n",
    "        \n",
    "        self.sma_bands_info = pd.concat([self.sma_bands_info, pd.DataFrame({\n",
    "            'function': ['Bollinger_Bands'],\n",
    "            'signal': [bbands_signal],\n",
    "            'period': [period],\n",
    "            'std': [std],\n",
    "            'lower_band': [lower_band],\n",
    "            'middle_band': [middle_band],\n",
    "            'upper_band': [upper_band]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    def get_rsi(self, data: pd.DataFrame, length: int = 25, overbought: int = 70, oversold: int = 30):\n",
    "        \"\"\"\n",
    "        This function calculates the RSI and generates a signal based on overbought/oversold levels.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - length: RSI period.\n",
    "        - overbought: RSI overbought threshold.\n",
    "        - oversold: RSI oversold threshold.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.rsi_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "\n",
    "        period, upper_level, lower_level = length, overbought, oversold \n",
    "\n",
    "        # Compute RSI\n",
    "        rsi = talib.RSI(data['Close'], timeperiod=length)\n",
    "        rsi_now = rsi.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if rsi_now >= overbought:\n",
    "            rsi_signal = 'Sell'\n",
    "        elif rsi_now <= oversold:\n",
    "            rsi_signal = 'Buy'\n",
    "        else:\n",
    "            rsi_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['RSI'],\n",
    "            'signal': [rsi_signal]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        self.rsi_info = pd.concat([self.rsi_info, pd.DataFrame({\n",
    "            'function': ['RSI'],\n",
    "            'signal': [rsi_signal],\n",
    "            'period': [period],\n",
    "            'upper_level': [upper_level],\n",
    "            'lower_level': [lower_level]\n",
    "        })], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class ParamsOptimization():\n",
    "    \"\"\"\n",
    "    A class for optimizing technical indicators' parameters and evaluating strategy performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.crossover_params = pd.DataFrame(columns=['Ticker', 'EMA1', 'EMA2', 'EMA3', 'Sharpe', 'MaxDrawdown', 'Expectancy'])\n",
    "        self.bbands_params = pd.DataFrame(columns=['Ticker', 'Period', 'Std', 'Sharpe', 'MaxDrawdown', 'Expectancy'])\n",
    "\n",
    "    def optimize(self, asset_type: str, symbol: str, period: str, interval: str):\n",
    "        \"\"\"\n",
    "        Run optimization for all strategies.\n",
    "        \"\"\"\n",
    "        data = self.fetch_data(asset_type, symbol, period, interval)\n",
    "        self.crossover_results = self.optimize_crossover(data, symbol)\n",
    "        self.bbands_results = self.optimize_bbands(data, symbol)\n",
    "\n",
    "\n",
    "    def fetch_data(self,asset_type: str, symbol : str, period : str, interval : str):\n",
    "        \"\"\"\n",
    "        Simulate fetching market data for the given ticker. According to same periodicity and timeframe of subject bot setting\n",
    "        \"\"\"\n",
    "\n",
    "        if asset_type == 'stock':\n",
    "            from backend.datasources.yahoodata import DataHistory\n",
    "            dh = DataHistory()\n",
    "            data = dh.get_yahoo_data_history(symbol, period, interval, start=datetime.now(), end=datetime.now() - timedelta(days=365))\n",
    "\n",
    "        elif asset_type == 'cambial':\n",
    "            pass\n",
    "            # Metatrader\n",
    "        elif asset_type == 'crypto':\n",
    "            pass\n",
    "            # crypto\n",
    "        return data\n",
    "\n",
    "    def optimize_crossover(self, data : pd.DataFrame, symbol : str):\n",
    "        \"\"\"\n",
    "        Optimize EMA crossover strategy.\n",
    "        \"\"\"\n",
    "        ema1_periods = range(10, 21)\n",
    "        ema2_periods = range(25, 61)\n",
    "        ema3_periods = range(100, 200)\n",
    "\n",
    "        combinations = list(itertools.product(ema1_periods, ema2_periods, ema3_periods))\n",
    "\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.simulate_crossover)(\n",
    "            data, symbol, l1, l2, l3) for l1, l2, l3 in tqdm(combinations, desc=\"Optimizing EMA Crossover\"))\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def simulate_crossover(self, data : pd.DataFrame, symbol : str, l1 : int, l2 : int, l3 : int):\n",
    "        \"\"\"\n",
    "        Simulate crossover strategy and calculate metrics.\n",
    "        \"\"\"\n",
    "        # Calculate EMAs\n",
    "        data['ema1'] = talib.EMA(data['Close'], timeperiod=l1)\n",
    "        data['ema2'] = talib.EMA(data['Close'], timeperiod=l2)\n",
    "        data['ema3'] = talib.EMA(data['Close'], timeperiod=l3)\n",
    "\n",
    "        # Generate signals\n",
    "        data['signal'] = np.where((data['ema1'] > data['ema2']) & (data['ema2'] > data['ema3']), 1,\n",
    "                                  np.where((data['ema1'] < data['ema2']) & (data['ema2'] < data['ema3']), -1, 0))\n",
    "        data['returns'] = data['Close'].pct_change() * data['signal'].shift(1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        sharpe = self.calculate_sharpe(data['returns'])\n",
    "        max_drawdown = self.calculate_max_drawdown(data['returns'])\n",
    "        expectancy = self.calculate_expectancy(data['returns'])\n",
    "\n",
    "        return {\n",
    "            'Ticker': symbol,\n",
    "            'EMA1': l1,\n",
    "            'EMA2': l2,\n",
    "            'EMA3': l3,\n",
    "            'Sharpe': sharpe,\n",
    "            'MaxDrawdown': max_drawdown,\n",
    "            'Expectancy': expectancy\n",
    "        }\n",
    "\n",
    "    def optimize_bbands(self, data : pd.DataFrame, symbol : str):\n",
    "        \"\"\"\n",
    "        Optimize Bollinger Bands strategy.\n",
    "        \"\"\"\n",
    "        sma_periods = range(10, 21)\n",
    "        std_devs = range(1, 3)\n",
    "\n",
    "        combinations = list(itertools.product(sma_periods, std_devs))\n",
    "\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.simulate_bbands)(\n",
    "            data, symbol, period, std) for period, std in tqdm(combinations, desc=\"Optimizing Bollinger Bands\"))\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "       \n",
    "        return results_df\n",
    "\n",
    "    def simulate_bbands(self, data, symbol, period, std):\n",
    "        \"\"\"\n",
    "        Simulate Bollinger Bands strategy and calculate metrics.\n",
    "        \"\"\"\n",
    "        # Calculate Bollinger Bands\n",
    "        upperband, middleband, lowerband = talib.BBANDS(\n",
    "            data['Close'], timeperiod=period, nbdevup=std, nbdevdn=std, matype=0\n",
    "        )\n",
    "\n",
    "        # Generate signals\n",
    "        data['signal'] = np.where(data['Close'] < lowerband, 1,\n",
    "                                  np.where(data['Close'] > upperband, -1, 0))\n",
    "        data['returns'] = data['Close'].pct_change() * data['signal'].shift(1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        sharpe = self.calculate_sharpe(data['returns'])\n",
    "        max_drawdown = self.calculate_max_drawdown(data['returns'])\n",
    "        expectancy = self.calculate_expectancy(data['returns'])\n",
    "\n",
    "        return {\n",
    "            'Ticker': symbol,\n",
    "            'Period': period,\n",
    "            'Std': std,\n",
    "            'Sharpe': sharpe,\n",
    "            'MaxDrawdown': max_drawdown,\n",
    "            'Expectancy': expectancy\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_sharpe(returns, risk_free_rate=0.025):\n",
    "        \"\"\"\n",
    "        Calculate Sharpe Ratio.\n",
    "        \"\"\"\n",
    "        mean_return = returns.mean()\n",
    "        std_dev = returns.std()\n",
    "        if std_dev == 0:\n",
    "            return 0\n",
    "        return (mean_return - risk_free_rate) / std_dev\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_max_drawdown(returns):\n",
    "        \"\"\"\n",
    "        Calculate Max Drawdown.\n",
    "        \"\"\"\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        running_max = cumulative.cummax()\n",
    "        drawdown = running_max - cumulative\n",
    "        return drawdown.max()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_expectancy(returns):\n",
    "        \"\"\"\n",
    "        Calculate Expectancy.\n",
    "        \"\"\"\n",
    "        wins = returns[returns > 0]\n",
    "        losses = returns[returns < 0]\n",
    "        win_rate = len(wins) / len(returns) if len(returns) > 0 else 0\n",
    "        loss_rate = 1 - win_rate\n",
    "        avg_win = wins.mean() if len(wins) > 0 else 0\n",
    "        avg_loss = losses.mean() if len(losses) > 0 else 0\n",
    "        return (win_rate * avg_win) - (loss_rate * avg_loss)\n",
    "\n",
    "# Adicionar Fontes Crypt e Cambial\n",
    "# Adicionar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_28416\\1446340434.py:100: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.sma_bands_info = pd.concat([self.sma_bands_info, pd.DataFrame({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bollinger_Bands</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crossover</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RSI</td>\n",
       "      <td>Flat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          function signal\n",
       "0  Bollinger_Bands   Sell\n",
       "1        Crossover    Buy\n",
       "2              RSI   Flat"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data\n",
    "\n",
    "tm = TrendMetrics()\n",
    "tm.get_sma_bands(data=df, length=15, std_dev=1)\n",
    "tm.get_crossover(data=df, l1=25, l2=50, l3=200)\n",
    "tm.get_rsi(data=df, length=25, overbought=70, oversold=30)\n",
    "\n",
    "tm.result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing EMA Crossover: 100%|██████████| 39600/39600 [00:11<00:00, 3312.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Otimização EMA Crossover:\n",
      "      Ticker  EMA1  EMA2  EMA3    Sharpe  MaxDrawdown  Expectancy\n",
      "0        SPY    10    25   100 -2.613950     0.303667    0.006992\n",
      "1        SPY    10    25   101 -2.617432     0.300424    0.006995\n",
      "2        SPY    10    25   102 -2.630023     0.290087    0.006981\n",
      "3        SPY    10    25   103 -2.633408     0.292406    0.006980\n",
      "4        SPY    10    25   104 -2.634544     0.300940    0.006974\n",
      "...      ...   ...   ...   ...       ...          ...         ...\n",
      "39595    SPY    20    60   195 -2.871977     0.474086    0.006832\n",
      "39596    SPY    20    60   196 -2.871949     0.477427    0.006837\n",
      "39597    SPY    20    60   197 -2.872561     0.474437    0.006838\n",
      "39598    SPY    20    60   198 -2.875468     0.465207    0.006835\n",
      "39599    SPY    20    60   199 -2.876874     0.472461    0.006831\n",
      "\n",
      "[39600 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Bollinger Bands: 100%|██████████| 22/22 [00:00<00:00, 10994.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados da Otimização Bollinger Bands:\n",
      "   Ticker  Period  Std    Sharpe  MaxDrawdown  Expectancy\n",
      "0     SPY      10    1 -2.962345     0.420373    0.006978\n",
      "1     SPY      10    2 -6.799412     0.157983    0.008256\n",
      "2     SPY      11    1 -2.860866     0.533861    0.007054\n",
      "3     SPY      11    2 -6.456669     0.159455    0.007891\n",
      "4     SPY      12    1 -2.809079     0.583004    0.007035\n",
      "5     SPY      12    2 -6.246475     0.123052    0.008021\n",
      "6     SPY      13    1 -2.814964     0.554000    0.007008\n",
      "7     SPY      13    2 -5.855324     0.119517    0.007864\n",
      "8     SPY      14    1 -2.840845     0.575541    0.006970\n",
      "9     SPY      14    2 -5.917115     0.113973    0.007216\n",
      "10    SPY      15    1 -2.854063     0.562334    0.006926\n",
      "11    SPY      15    2 -5.924271     0.115390    0.007134\n",
      "12    SPY      16    1 -2.840299     0.513837    0.006951\n",
      "13    SPY      16    2 -5.921385     0.123770    0.007015\n",
      "14    SPY      17    1 -2.838378     0.523457    0.006951\n",
      "15    SPY      17    2 -5.839987     0.123308    0.007007\n",
      "16    SPY      18    1 -2.849458     0.572846    0.006901\n",
      "17    SPY      18    2 -5.761735     0.110701    0.006851\n",
      "18    SPY      19    1 -2.836316     0.579756    0.006881\n",
      "19    SPY      19    2 -5.854253     0.139096    0.006782\n",
      "20    SPY      20    1 -2.831535     0.594481    0.006845\n",
      "21    SPY      20    2 -5.820352     0.082902    0.006642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instanciar a classe\n",
    "optimizer = ParamsOptimization()\n",
    "\n",
    "# Testar otimização de EMA crossover\n",
    "crossover_results = optimizer.optimize_crossover(data, symbol=symbol)\n",
    "print(\"Resultados da Otimização EMA Crossover:\")\n",
    "print(crossover_results)\n",
    "\n",
    "# Testar otimização de Bollinger Bands\n",
    "bbands_results = optimizer.optimize_bbands(data, symbol=symbol)\n",
    "print(\"\\nResultados da Otimização Bollinger Bands:\")\n",
    "print(bbands_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo Tables scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Symbol                        Name     Price  Change  Change %    Volume  \\\n",
      "0   INTC           Intel Corporation     24.13    1.65      7.34  242.162M   \n",
      "1   NVDA          NVIDIA Corporation    135.29    4.15      3.16  195.623M   \n",
      "2   LCID           Lucid Group, Inc.    3.2600    0.39     13.59  143.291M   \n",
      "3   BBAI   BigBear.ai Holdings, Inc.      9.78    0.04      0.41  124.756M   \n",
      "4   SMCI  Super Micro Computer, Inc.     42.28    2.60      6.55  109.701M   \n",
      "\n",
      "  Avg Vol (3M) Market Cap  P/E Ratio (TTM)  52 Wk Change % 52 Wk Range  \n",
      "0      74.418M   104.483B             0.00          -48.97              \n",
      "1     245.113M     3.313T            53.47           80.49              \n",
      "2      86.335M     9.818B             0.00          -20.94              \n",
      "3      55.417M      2.46B             0.00          332.89              \n",
      "4      72.996M    24.758B            21.03          -60.48              \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_yahoo_most_active(self, table_class: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extrat data from yahoo most active\n",
    "\n",
    "    Parameters:\n",
    "        classe_tabela (str): Classe CSS da tabela para extração (opcional).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with table content.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://finance.yahoo.com/markets/stocks/most-active/\")\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        if table_class:\n",
    "            tabela = soup.find('table', {'class': table_class})\n",
    "        else:\n",
    "            tabela = soup.find('table')\n",
    "\n",
    "        headers = [th.text.strip() for th in tabela.find_all('th')]\n",
    "\n",
    "        rows = []\n",
    "        for row in tabela.find_all('tr')[1:]:\n",
    "            cols = [td.text.strip() for td in row.find_all('td')]\n",
    "            if cols: \n",
    "                rows.append(cols)\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=headers if headers else None)\n",
    "        df[\"Price\"] = df[\"Price\"].str.extract(r\"^([\\d\\.]+)\")\n",
    "        df[\"Change\"] = df[\"Change\"].str.replace(\"+\", \"\", regex=False).astype(float)\n",
    "        df[\"Change %\"] = df[\"Change %\"].str.replace(\"%\", \"\", regex=False).astype(float)\n",
    "        df[\"P/E Ratio (TTM)\"] = df[\"P/E Ratio (TTM)\"].str.replace(\"-\", \"0\", regex=False).astype(float)\n",
    "        df[\"52 Wk Change %\"] = df[\"52 Wk Change %\"].str.replace(\"%\", \"\", regex=False).astype(float)\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error accessing URL: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "\n",
    "    return pd.DataFrame()\n",
    "\n",
    "df = get_yahoo_most_active(self)\n",
    "print(df.head())  # Exibe as primeiras linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Empty DataFrame\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL da página das ações mais ativas\n",
    "url = 'https://finance.yahoo.com/markets/stocks/most-active/'\n",
    "\n",
    "# Cabeçalhos para a requisição HTTP\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "# Fazer a requisição HTTP para obter o conteúdo da página\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Verificar se a requisição foi bem-sucedida\n",
    "if response.status_code == 200:\n",
    "    # Analisar o conteúdo da página com o BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Encontrar todas as linhas da tabela de ações mais ativas\n",
    "    rows = soup.find_all('tr', attrs={'class': 'simpTblRow'})\n",
    "\n",
    "    # Iterar sobre as linhas e extrair as informações desejadas\n",
    "    for row in rows:\n",
    "        symbol = row.find('td', attrs={'aria-label': 'Symbol'}).text\n",
    "        name = row.find('td', attrs={'aria-label': 'Name'}).text\n",
    "        price = row.find('td', attrs={'aria-label': 'Last Price'}).text\n",
    "        change = row.find('td', attrs={'aria-label': 'Change'}).text\n",
    "        percent_change = row.find('td', attrs={'aria-label': '% Change'}).text\n",
    "        volume = row.find('td', attrs={'aria-label': 'Volume'}).text\n",
    "\n",
    "        # Exibir as informações extraídas\n",
    "        print(f'Símbolo: {symbol}')\n",
    "        print(f'Nome: {name}')\n",
    "        print(f'Preço: {price}')\n",
    "        print(f'Variação: {change}')\n",
    "        print(f'Variação (%): {percent_change}')\n",
    "        print(f'Volume: {volume}')\n",
    "        print('-----------------------------')\n",
    "else:\n",
    "    print(f'Falha ao acessar a página. Status code: {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection Binance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.binance.com/api/v3/ticker/price\"\n",
    "params = {\"symbol\": \"BTCUSDT\"}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    symbol = response.json()[\"symbol\"]\n",
    "    price = response.json()[\"price\"]\n",
    "else:\n",
    "    error = response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_crypto_symbol_24h(symbol : str):\n",
    "\n",
    "    url = \"https://api.binance.com/api/v3/ticker/24hr\"\n",
    "    params = {\"symbol\": symbol}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        priceChangePercent = Decimal(response.json()[\"priceChangePercent\"])\n",
    "        weightedAvgPrice = Decimal(response.json()[\"weightedAvgPrice\"])\n",
    "        prevClosePrice = Decimal(response.json()[\"prevClosePrice\"])\n",
    "        priceChange = Decimal(response.json()[\"priceChange\"])\n",
    "        lastPrice = Decimal(response.json()[\"lastPrice\"])\n",
    "        lastQty = Decimal(response.json()[\"lastQty\"])\n",
    "        bidPrice = Decimal(response.json()[\"bidPrice\"])\n",
    "        bidQty = Decimal(response.json()[\"bidQty\"])\n",
    "        askPrice = Decimal(response.json()[\"askPrice\"])\n",
    "        askQty = Decimal(response.json()[\"askQty\"])\n",
    "        openPrice = Decimal(response.json()[\"openPrice\"])\n",
    "        highPrice = Decimal(response.json()[\"highPrice\"])\n",
    "        lowPrice = Decimal(response.json()[\"lowPrice\"])\n",
    "        volume = Decimal(response.json()[\"volume\"])\n",
    "        quoteVolume = Decimal(response.json()[\"quoteVolume\"])\n",
    "        openTime = datetime.fromtimestamp(response.json()[\"openTime\"] / 1000).strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "        closeTime = datetime.fromtimestamp(response.json()[\"closeTime\"] / 1000).strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "        firstId = response.json()[\"firstId\"]\n",
    "        lastId = response.json()[\"lastId\"]\n",
    "        count = response.json()[\"count\"]\n",
    "    else:\n",
    "        print(f\"Erro: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': -1102,\n",
       " 'msg': \"Mandatory parameter 'signature' was not sent, was empty/null, or malformed.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.binance.com/api/v3/openOrders\"\n",
    "params = {\"symbol\": \"BTCUSDT\"}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "response.json()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
