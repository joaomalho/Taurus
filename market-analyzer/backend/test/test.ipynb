{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar objeto do ticker\n",
    "ticker_data = yf.Ticker(\"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Não Funciona ####\n",
    "# # Acessar fast_info\n",
    "info = ticker_data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_symbol_recommendations = ticker_data.recommendations\n",
    "# yahoo_symbol_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividendos\n",
    "cashflow = ticker_data.cashflow\n",
    "# cashflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notícias\n",
    "balance_sheet = ticker_data.balance_sheet\n",
    "# balance_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_symbol_sustainability = ticker_data.sustainability\n",
    "# yahoo_symbol_sustainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventos corporativos\n",
    "calendar = ticker_data.calendar\n",
    "# calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Datas disponíveis para opções\n",
    "# options_dates = ticker_data.options\n",
    "# print(\"Datas de opções:\", options_dates)\n",
    "\n",
    "# # Obter opções para uma data específica\n",
    "# options = ticker_data.option_chain(options_dates[0])\n",
    "# print(\"Opções de compra (calls):\", options.calls)\n",
    "# print(\"Opções de venda (puts):\", options.puts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Demonstrativo financeiro\n",
    "# financials = ticker_data.financials\n",
    "# print(\"Demonstrativo financeiro:\", financials)\n",
    "\n",
    "# # Balanço patrimonial\n",
    "# balance_sheet = ticker_data.balance_sheet\n",
    "# print(\"Balanço patrimonial:\", balance_sheet)\n",
    "\n",
    "# # Fluxo de caixa\n",
    "# cashflow = ticker_data.cashflow\n",
    "# print(\"Fluxo de caixa:\", cashflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informações financeiras mais detalhadas da empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dados de sustentabilidade\n",
    "# sustainability = ticker_data.sustainability\n",
    "# print(sustainability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informações de ESG (Environmental, Social, Governance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ações em circulação\n",
    "# shares = ticker_data.shares\n",
    "# print(\"Ações em circulação:\", shares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenha informações sobre ações em circulação e histórico de splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principais investidores institucionais\n",
    "inst_holders = ticker_data.institutional_holders\n",
    "# inst_holders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados sobre investidores institucionais e sua participação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principais investidores institucionais\n",
    "holders = ticker_data.major_holders\n",
    "# holders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_data_history(symbol : str, period : str, interval: str, start = '1900-01-01', end = datetime.now(), prepost : bool = True):\n",
    "        '''\n",
    "        Data collection from yahoo\n",
    "\n",
    "        Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime, inclusive. Default is 1900-01-01 E.g. for start=\"2020-01-01\", the first data point will be on \"2020-01-01\"\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime, exclusive. Default is now E.g. for end=\"2023-01-01\", the last data point will be on \"2022-12-31\"\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results? Default is False\n",
    "        debug: bool\n",
    "            If passed as False, will suppress error message printing to console.\n",
    "        '''\n",
    "        yahoo_data_history = yf.Ticker(symbol).history(period=period, interval=interval, start=start, end=end, prepost=prepost)\n",
    "        return yahoo_data_history\n",
    "\n",
    "history = get_yahoo_data_history(symbol=\"MSFT\",period='1y', interval='1d', end = datetime.now(), prepost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned Data: {'data': {'companies': []}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the endpoint and your API key\n",
    "url = \"https://api.simplywall.st/graphql\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer sws:ZGE4YzBlNzItMTg2Ni00Y2Y5LWI3YTktYzAxODcyZGEwZjE3OmFjODUzODRhZDUzNGMwMzY=\",\n",
    "    \"Content-Type\": \"application/json\",  # Required for JSON body\n",
    "}\n",
    "\n",
    "# Define the GraphQL query and variables\n",
    "query = \"\"\"\n",
    "query Companies($exchange: String!, $offset: Int!, $limit: Int!) {\n",
    "  companies(exchange: $exchange, offset: $offset, limit: $limit) {\n",
    "    id\n",
    "    exchangeSymbol\n",
    "    tickerSymbol\n",
    "    name\n",
    "    marketCapUSD\n",
    "    primaryIndustry { name }\n",
    "    secondaryIndustry { name }\n",
    "    tertiaryIndustry { name }\n",
    "    market { name iso2 }\n",
    "    closingPrices\n",
    "    statements { name title area type value outcome description state severity outcomeName }\n",
    "    listings { id exchangeSymbol tickerSymbol name marketCapUSD primaryIndustry { name } secondaryIndustry { name } tertiaryIndustry { name } market { name iso2 } closingPrices }\n",
    "    owners { name type sharesHeld percentOfSharesOutstanding holdingDate periodStartDate periodEndDate }\n",
    "    insiderTransactions { type ownerName ownerType description tradeDateMin tradeDateMax shares priceMin priceMax transactionValue percentageSharesTraded }\n",
    "    members { age name title tenure compensation }\n",
    "    active classificationStatus\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Define the variables for the query\n",
    "variables = {\n",
    "    \"exchange\": \"NYSE\",  # Try changing to \"NYSE\" or another exchange\n",
    "    \"offset\": 20,         # Try adjusting this value (e.g., 10 or 20)\n",
    "    \"limit\": 100          # Adjust limit to fetch more results\n",
    "}\n",
    "\n",
    "# Create the request payload\n",
    "payload = {\n",
    "    \"query\": query,\n",
    "    \"variables\": variables\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        print(\"No companies found with the given parameters.\")\n",
    "    else:\n",
    "        print(\"Returned Data:\", data)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando instalação do TA-Lib no Windows...\n",
      "O arquivo TA_Lib-0.5.1-cp311-cp311-win_amd64.whl já existe. Pulando o download.\n",
      "Instalando TA_Lib-0.5.1-cp311-cp311-win_amd64.whl...\n",
      "TA-Lib instalado com sucesso!\n",
      "Arquivo x:\\Taurus\\market-analyzer\\backend\\test\\TA_Lib-0.5.1-cp311-cp311-win_amd64.whl removido após a instalação.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "\n",
    "class TALibInstaller:\n",
    "    def install_ta_lib_windows(self):\n",
    "        \"\"\"Automatiza a instalação do TA-Lib no Windows.\"\"\"\n",
    "        print(\"Iniciando instalação do TA-Lib no Windows...\")\n",
    "\n",
    "        # URL do arquivo .whl (atualize conforme necessário)\n",
    "        talib_url = \"https://github.com/cgohlke/talib-build/releases/download/v0.5.1/TA_Lib-0.5.1-cp311-cp311-win_amd64.whl\"\n",
    "        talib_whl = talib_url.split(\"/\")[-1]  # Nome do arquivo\n",
    "\n",
    "        # Caminho local para salvar o arquivo .whl\n",
    "        local_path = os.path.join(os.getcwd(), \"libraries\")\n",
    "\n",
    "        # Fazer o download do arquivo .whl\n",
    "        if not os.path.exists(local_path):\n",
    "            print(f\"Baixando {talib_whl} de {talib_url}...\")\n",
    "            response = requests.get(talib_url, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(local_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(chunk_size=1024):\n",
    "                        f.write(chunk)\n",
    "                print(f\"Download concluído: {local_path}\")\n",
    "            else:\n",
    "                print(f\"Erro ao baixar {talib_url}: {response.status_code}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"O arquivo {talib_whl} já existe. Pulando o download.\")\n",
    "\n",
    "        # Instalar o arquivo .whl com pip\n",
    "        print(f\"Instalando {talib_whl}...\")\n",
    "        try:\n",
    "            subprocess.check_call([\"pip\", \"install\", local_path])\n",
    "            print(\"TA-Lib instalado com sucesso!\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Erro durante a instalação: {e}\")\n",
    "            return False\n",
    "\n",
    "        # Remover o arquivo .whl após a instalação (opcional)\n",
    "        if os.path.exists(local_path):\n",
    "            os.remove(local_path)\n",
    "            print(f\"Arquivo {local_path} removido após a instalação.\")\n",
    "        return True\n",
    "\n",
    "\n",
    "# Uso\n",
    "if __name__ == \"__main__\":\n",
    "    installer = TALibInstaller()\n",
    "    installer.install_ta_lib_windows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "\n",
    "class CandlesPatterns:\n",
    "    \"\"\"\n",
    "    Detect all candlestick patterns using TA-Lib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.result_candles_df = pd.DataFrame(columns=['Pattern', 'Signal', 'Relevance', 'Stoploss'])\n",
    "        \n",
    "\n",
    "    def detect_pattern(self, data: pd.DataFrame, pattern_function, pattern_name: str):\n",
    "        \"\"\"\n",
    "        General method to detect a specific candlestick pattern.\n",
    "        \"\"\"\n",
    "        data_pass = data  # Usar todos os candles fornecidos\n",
    "\n",
    "        # Detect pattern\n",
    "        detection = pattern_function(data_pass['Open'], data_pass['High'], data_pass['Low'], data_pass['Close'])\n",
    "\n",
    "        non_zero_detection = detection[detection != 0]\n",
    "        if not non_zero_detection.empty:\n",
    "            for date, signal in non_zero_detection.items():\n",
    "                # Cálculo do Stoploss baseado no padrão\n",
    "                if pattern_name in [\n",
    "                    \"doji\", \"dragonfly_doji\", \"gravestone_doji\", \"engulfing\",\n",
    "                    \"morning_star\", \"evening_star\", \"marubozu\", \"harami\",\n",
    "                    \"harami_cross\", \"kicking\", \"kicking_by_length\", \"tasuki_gap\",\n",
    "                    \"gap_side_by_side_white\", \"counter_attack\", \"piercing\",\n",
    "                    \"dark_cloud_cover\", \"tri_star\"\n",
    "                ]:\n",
    "                    stoploss = data_pass.loc[date, 'Low'] if signal > 0 else data_pass.loc[date, 'High']\n",
    "                elif pattern_name in [\n",
    "                    \"morning_doji_star\", \"hammer\", \"inverted_hammer\",\n",
    "                    \"thrusting\", \"matching_low\", \"three_white_soldiers\",\n",
    "                    \"three_outside\", \"three_stars_in_south\"\n",
    "                ]:\n",
    "                    stoploss = data_pass.loc[date, 'Low']\n",
    "                elif pattern_name in [\n",
    "                    \"evening_doji_star\", \"hanging_man\", \"shooting_star\",\n",
    "                    \"on_neck\", \"in_neck\", \"three_black_crows\",\n",
    "                    \"three_inside\", \"advance_block\", \"stalled_pattern\"\n",
    "                ]:\n",
    "                    stoploss = data_pass.loc[date, 'High']\n",
    "                else:\n",
    "                    stoploss = None\n",
    "\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'Pattern': [pattern_name],\n",
    "                    'Signal': [signal],\n",
    "                    'Relevance': ['Flat'],\n",
    "                    'Stoploss': [stoploss],\n",
    "                }, index=[date])\n",
    "                self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n",
    "\n",
    "        return detection\n",
    "\n",
    "    def doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDOJI, \"doji\")\n",
    "\n",
    "    def dragonfly_doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDRAGONFLYDOJI, \"dragonfly_doji\")\n",
    "\n",
    "    def gravestone_doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLGRAVESTONEDOJI, \"gravestone_doji\")\n",
    "\n",
    "    def engulfing(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLENGULFING, \"engulfing\")\n",
    "\n",
    "    def morning_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLMORNINGSTAR, \"morning_star\")\n",
    "\n",
    "    def evening_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLEVENINGSTAR, \"evening_star\")\n",
    "\n",
    "    def morning_doji_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMORNINGDOJISTAR, \"morning_doji_star\")\n",
    "\n",
    "    def evening_doji_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLEVENINGDOJISTAR, \"evening_doji_star\")\n",
    "\n",
    "    def hammer(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLHAMMER, \"hammer\")\n",
    "\n",
    "    def inverted_hammer(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLINVERTEDHAMMER, \"inverted_hammer\")\n",
    "\n",
    "    def hanging_man(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLHANGINGMAN, \"hanging_man\")\n",
    "\n",
    "    def shooting_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLSHOOTINGSTAR, \"shooting_star\")\n",
    "\n",
    "    def marubozu(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMARUBOZU, \"marubozu\")\n",
    "\n",
    "    def harami(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLHARAMI, \"harami\")\n",
    "\n",
    "    def harami_cross(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLHARAMICROSS, \"harami_cross\")\n",
    "\n",
    "    def spinning_top(self, data: pd.DataFrame):\n",
    "        '''\n",
    "        NEED FIBONACCI\n",
    "        '''\n",
    "        return self.detect_pattern(data, talib.CDLSPINNINGTOP, \"spinning_top\")\n",
    "\n",
    "    def kicking(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLKICKING, \"kicking\")\n",
    "\n",
    "    def kicking_by_length(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLKICKINGBYLENGTH, \"kicking_by_length\")\n",
    "\n",
    "    def tasuki_gap(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTASUKIGAP, \"tasuki_gap\")\n",
    "\n",
    "    def gap_side_by_side_white(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLGAPSIDESIDEWHITE, \"gap_side_by_side_white\")\n",
    "\n",
    "    def counter_attack(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLCOUNTERATTACK, \"counter_attack\")\n",
    "\n",
    "    def piercing(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLPIERCING, \"piercing\")\n",
    "\n",
    "    def dark_cloud_cover(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDARKCLOUDCOVER, \"dark_cloud_cover\")\n",
    "\n",
    "    def tri_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTRISTAR, \"tri_star\")\n",
    "\n",
    "    def on_neck(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLONNECK, \"on_neck\")\n",
    "\n",
    "    def in_neck(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLINNECK, \"in_neck\")\n",
    "\n",
    "    def thrusting(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTHRUSTING, \"thrusting\")\n",
    "\n",
    "    def matching_low(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMATCHINGLOW, \"matching_low\")\n",
    "\n",
    "    def three_black_crows(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3BLACKCROWS, \"three_black_crows\")\n",
    "\n",
    "    def three_white_soldiers(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3WHITESOLDIERS, \"three_white_soldiers\")\n",
    "\n",
    "    def three_inside(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3INSIDE, \"three_inside\")\n",
    "\n",
    "    def three_outside(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3OUTSIDE, \"three_outside\")\n",
    "\n",
    "    def three_stars_in_south(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3STARSINSOUTH, \"three_stars_in_south\")\n",
    "\n",
    "    def advance_block(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLADVANCEBLOCK, \"advance_block\")\n",
    "\n",
    "    def stalled_pattern(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLSTALLEDPATTERN, \"stalled_pattern\")\n",
    "\n",
    "    # def abandoned_baby(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLABANDONEDBABY, \"abandoned_baby\")\n",
    "\n",
    "    # def unique_3_river(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLUNIQUE3RIVER, \"unique_3_river\")\n",
    "\n",
    "    # def belt_hold(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLBELTHOLD, \"belt_hold\")\n",
    "\n",
    "    # def separating_lines(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLSEPARATINGLINES, \"Separating Lines\")\n",
    "\n",
    "    # def upside_gap_two_crows(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLUPSIDEGAP2CROWS, \"Upside Gap Two Crows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_37952\\76382768.py:55: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_37952\\76382768.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Detected Patterns with Stoploss:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Stoploss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-03 00:00:00-05:00</th>\n",
       "      <td>advance_block</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>171.326739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 00:00:00-04:00</th>\n",
       "      <td>advance_block</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>182.367738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-29 00:00:00-04:00</th>\n",
       "      <td>advance_block</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>207.445748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-06 00:00:00-04:00</th>\n",
       "      <td>advance_block</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>256.643626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-16 00:00:00-04:00</th>\n",
       "      <td>advance_block</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>416.251438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-22 00:00:00-04:00</th>\n",
       "      <td>tri_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>165.761221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-11 00:00:00-04:00</th>\n",
       "      <td>tri_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>206.891511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-14 00:00:00-04:00</th>\n",
       "      <td>tri_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>264.967737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-17 00:00:00-04:00</th>\n",
       "      <td>tri_star</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>264.282350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-27 00:00:00-05:00</th>\n",
       "      <td>tri_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>447.905301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Pattern Signal Relevance    Stoploss\n",
       "2016-03-03 00:00:00-05:00  advance_block   -100      Flat  171.326739\n",
       "2016-07-01 00:00:00-04:00  advance_block   -100      Flat  182.367738\n",
       "2017-03-29 00:00:00-04:00  advance_block   -100      Flat  207.445748\n",
       "2018-08-06 00:00:00-04:00  advance_block   -100      Flat  256.643626\n",
       "2022-08-16 00:00:00-04:00  advance_block   -100      Flat  416.251438\n",
       "...                                  ...    ...       ...         ...\n",
       "2015-09-22 00:00:00-04:00       tri_star   -100      Flat  165.761221\n",
       "2017-04-11 00:00:00-04:00       tri_star   -100      Flat  206.891511\n",
       "2019-06-14 00:00:00-04:00       tri_star   -100      Flat  264.967737\n",
       "2019-06-17 00:00:00-04:00       tri_star    100      Flat  264.282350\n",
       "2023-11-27 00:00:00-05:00       tri_star   -100      Flat  447.905301\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "start, end = '2015-01-01', '2024-07-05'\n",
    "\n",
    "data = yf.Ticker('SPY').history(period='1y', interval='1d', start=start, end=end)\n",
    "\n",
    "cm = CandlesPatterns()\n",
    "\n",
    "# Loop para detectar padrões\n",
    "for candle_function in dir(cm):\n",
    "    if (not candle_function.startswith(\"__\") and \n",
    "        callable(getattr(cm, candle_function)) and \n",
    "        candle_function != \"detect_pattern\"):\n",
    "        pattern_function = getattr(cm, candle_function)\n",
    "        try:\n",
    "            candle_result = pattern_function(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting pattern {candle_function}: {e}\")\n",
    "\n",
    "# Verificar padrões detectados e valores de stoploss\n",
    "print(\"\\nAll Detected Patterns with Stoploss:\")\n",
    "cm.result_candles_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "\n",
    "class TrendMetrics():\n",
    "    \"\"\"\n",
    "    A class that encapsulates technical analysis metrics using TA-Lib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.result_df = pd.DataFrame(columns=['function', 'signal'])\n",
    "        self.crossover_info = pd.DataFrame(columns=['function', 'signal', 'period_low', 'period_mid', 'period_high', 'ema_low', 'ema_mid', 'ema_high'])\n",
    "        self.sma_bands_info = pd.DataFrame(columns=['function', 'signal', 'period', 'std', 'lower_band', 'middle_band', 'upper_band'])\n",
    "        self.rsi_info = pd.DataFrame(columns=['function', 'signal', 'period', 'upper_level', 'lower_level'])\n",
    "\n",
    "    def get_crossover(self, data: pd.DataFrame, l1: int, l2: int, l3: int):\n",
    "        \"\"\"\n",
    "        This function measures the crossover of 3 EMAs using TA-Lib.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - l1, l2, l3: Periods for the 3 EMAs.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.crossover_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "        period_low, period_mid, period_high = l1, l2, l3\n",
    "        \n",
    "        # Compute EMAs\n",
    "        ema1 = talib.EMA(data['Close'], timeperiod=l1)\n",
    "        ema2 = talib.EMA(data['Close'], timeperiod=l2)\n",
    "        ema3 = talib.EMA(data['Close'], timeperiod=l3)\n",
    "\n",
    "        # Current values\n",
    "        ema_low, ema_mid, ema_high = ema1.iloc[-1], ema2.iloc[-1], ema3.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if ema_low > ema_mid > ema_high:\n",
    "            crossover_signal = 'Buy'\n",
    "        elif ema_low < ema_mid < ema_high:\n",
    "            crossover_signal = 'Sell'\n",
    "        else:\n",
    "            crossover_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['Crossover'],\n",
    "            'signal': [crossover_signal]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        # Save result\n",
    "        self.crossover_info = pd.concat([self.crossover_info, pd.DataFrame({\n",
    "            'function': ['Crossover'],\n",
    "            'signal': [crossover_signal],\n",
    "            'period_low': [period_low],\n",
    "            'period_mid': [period_mid],\n",
    "            'period_high': [period_high],\n",
    "            'ema1_now': [ema_low],\n",
    "            'ema2_now': [ema_mid],\n",
    "            'ema3_now': [ema_high],\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    def get_sma_bands(self, data: pd.DataFrame, length: int=15, std_dev: int = 1):\n",
    "        \"\"\"\n",
    "        This function calculates Bollinger Bands and detects signals based on them.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - length: SMA period.\n",
    "        - std_dev: Number of standard deviations for the bands.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.bbands_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "\n",
    "        period, std = length, std_dev\n",
    "\n",
    "        # Compute Bollinger Bands\n",
    "        upper_band, middle_band, lower_band = talib.BBANDS(\n",
    "            data['Close'], timeperiod=length, nbdevup=std_dev, nbdevdn=std_dev, matype=0\n",
    "        )\n",
    "\n",
    "        # Current values\n",
    "        last_close = data['Close'].iloc[-1]\n",
    "        lower_band, middle_band, upper_band = lower_band.iloc[-1], middle_band.iloc[-1], upper_band.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if last_close <= lower_band:\n",
    "            bbands_signal = 'Buy'\n",
    "        elif last_close >= upper_band:\n",
    "            bbands_signal = 'Sell'\n",
    "        else:\n",
    "            bbands_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['Bollinger_Bands'],\n",
    "            'signal': [bbands_signal]\n",
    "        })], ignore_index=True)\n",
    "        \n",
    "        self.sma_bands_info = pd.concat([self.sma_bands_info, pd.DataFrame({\n",
    "            'function': ['Bollinger_Bands'],\n",
    "            'signal': [bbands_signal],\n",
    "            'period': [period],\n",
    "            'std': [std],\n",
    "            'lower_band': [lower_band],\n",
    "            'middle_band': [middle_band],\n",
    "            'upper_band': [upper_band]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "\n",
    "    def get_rsi(self, data: pd.DataFrame, length: int = 25, overbought: int = 70, oversold: int = 30):\n",
    "        \"\"\"\n",
    "        This function calculates the RSI and generates a signal based on overbought/oversold levels.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - length: RSI period.\n",
    "        - overbought: RSI overbought threshold.\n",
    "        - oversold: RSI oversold threshold.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.rsi_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "\n",
    "        period, upper_level, lower_level = length, overbought, oversold \n",
    "\n",
    "        # Compute RSI\n",
    "        rsi = talib.RSI(data['Close'], timeperiod=length)\n",
    "        rsi_now = rsi.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if rsi_now >= overbought:\n",
    "            rsi_signal = 'Sell'\n",
    "        elif rsi_now <= oversold:\n",
    "            rsi_signal = 'Buy'\n",
    "        else:\n",
    "            rsi_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['RSI'],\n",
    "            'signal': [rsi_signal]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        self.rsi_info = pd.concat([self.rsi_info, pd.DataFrame({\n",
    "            'function': ['RSI'],\n",
    "            'signal': [rsi_signal],\n",
    "            'period': [period],\n",
    "            'upper_level': [upper_level],\n",
    "            'lower_level': [lower_level]\n",
    "        })], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n",
    "\n",
    "\n",
    "class DataHistory():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self\n",
    "    \n",
    "    def get_yahoo_data_history(self, symbol : str, period : str, interval : str, start = '1900-01-01', end = datetime.now(), prepost : bool = True):\n",
    "        '''\n",
    "        Data collection from yahoo\n",
    "\n",
    "        Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime, inclusive. Default is 1900-01-01 E.g. for start=\"2020-01-01\", the first data point will be on \"2020-01-01\"\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime, exclusive. Default is now E.g. for end=\"2023-01-01\", the last data point will be on \"2022-12-31\"\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results? Default is False\n",
    "        '''\n",
    "        yahoo_data_history = yf.Ticker(symbol).history(period=period, interval=interval, start=start, end=end, prepost=prepost)\n",
    "        return yahoo_data_history\n",
    "    \n",
    "    def get_yahoo_symbol_info(self, symbol : str):\n",
    "        '''\n",
    "        Return detailed information about asset\n",
    "        '''\n",
    "        yahoo_symbol_info = yf.Ticker(symbol).info\n",
    "        return yahoo_symbol_info\n",
    "    \n",
    "    def get_yahoo_symbol_dividends(self, symbol : str):\n",
    "        '''\n",
    "        Return dividents historics\n",
    "        '''\n",
    "        yahoo_symbol_dividends = yf.Ticker(symbol).dividends\n",
    "        return yahoo_symbol_dividends\n",
    "    \n",
    "    def get_yahoo_symbol_splits(self, symbol : str):\n",
    "        '''\n",
    "        Return actions splits historics\n",
    "        '''\n",
    "        yahoo_symbol_splits = yf.Ticker(symbol).splits\n",
    "        return yahoo_symbol_splits\n",
    " \n",
    "    def get_yahoo_symbol_recommendations(self, symbol : str):\n",
    "        '''\n",
    "        Return recommendations about asset\n",
    "        '''\n",
    "        yahoo_symbol_recommendations = yf.Ticker(symbol).recommendations\n",
    "        return yahoo_symbol_recommendations\n",
    "\n",
    "    def get_yahoo_symbol_calendar(self, symbol : str):\n",
    "        '''\n",
    "        Return corporative calendar events about asset\n",
    "        '''\n",
    "        yahoo_symbol_calendar = yf.Ticker(symbol).calendar\n",
    "        return yahoo_symbol_calendar\n",
    "\n",
    "    def get_yahoo_symbol_major_holders(self, symbol : str):\n",
    "        '''\n",
    "        Return the list of major holders\n",
    "        '''\n",
    "        yahoo_symbol_major_holders = yf.Ticker(symbol).major_holders\n",
    "        return yahoo_symbol_major_holders\n",
    "\n",
    "    def get_yahoo_symbol_institutional_holders(self, symbol : str):\n",
    "        '''\n",
    "        Return the list of major institutional holders\n",
    "        '''\n",
    "        yahoo_symbol_institutional_holders = yf.Ticker(symbol).institutional_holders\n",
    "        return yahoo_symbol_institutional_holders\n",
    "\n",
    "    def get_yahoo_symbol_balance_sheet(self, symbol : str):\n",
    "        '''\n",
    "        Return the patrimonial balance sheet\n",
    "        '''\n",
    "        yahoo_symbol_balance_sheet = yf.Ticker(symbol).balance_sheet\n",
    "        return yahoo_symbol_balance_sheet\n",
    "\n",
    "    def get_yahoo_symbol_financials(self, symbol : str):\n",
    "        '''\n",
    "        !!! Not Working !!!\n",
    "        Return the financials results (profits and expenses)\n",
    "        '''\n",
    "        yahoo_symbol_financials = yf.Ticker(symbol).financials\n",
    "        return yahoo_symbol_financials\n",
    "\n",
    "    def get_yahoo_symbol_cashflow(self, symbol : str):\n",
    "        '''\n",
    "        Return the cashflow results\n",
    "        '''\n",
    "        yahoo_symbol_cashflow = yf.Ticker(symbol).cashflow\n",
    "        return yahoo_symbol_cashflow\n",
    "\n",
    "    def get_yahoo_symbol_sustainability(self, symbol : str):\n",
    "        '''\n",
    "        \n",
    "        Return the ESG metrics (enviormental, social and governamental)\n",
    "        '''\n",
    "        yahoo_symbol_sustainability = yf.Ticker(symbol).sustainability\n",
    "        return yahoo_symbol_sustainability\n",
    "\n",
    "    def get_yahoo_symbol_news(self, symbol : str):\n",
    "        '''\n",
    "        Return the latest news about asset\n",
    "        '''\n",
    "        yahoo_symbol_news = yf.Ticker(symbol).news\n",
    "        return yahoo_symbol_news\n",
    "\n",
    "    def get_yahoo_symbol_fast_info(self, symbol : str):\n",
    "        '''\n",
    "        Return the fast information about asset\n",
    "\n",
    "        Data:\n",
    "        exchange : str\n",
    "            Exchange on which the asset is traded\n",
    "        marketCap : float\n",
    "            Marker Cap of asset\n",
    "        quoteType: str\n",
    "            Asset type (EQUITY, CRYPTO, FOREX..)\n",
    "        shares : int\n",
    "            Total Number of shares in circulation            \n",
    "        '''\n",
    "        yahoo_symbol_fast_info_exchange = yf.Ticker(symbol).fast_info.exchange\n",
    "        yahoo_symbol_fast_info_marketcap = yf.Ticker(symbol).fast_info.market_cap\n",
    "        yahoo_symbol_fast_info_quotetype = yf.Ticker(symbol).fast_info.quote_type\n",
    "        yahoo_symbol_fast_info_shares = yf.Ticker(symbol).fast_info.shares\n",
    "        return yahoo_symbol_fast_info_exchange, yahoo_symbol_fast_info_marketcap, yahoo_symbol_fast_info_quotetype, yahoo_symbol_fast_info_shares\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Results df -------------\n",
      "\n",
      "           function signal\n",
      "0        Crossover    Buy\n",
      "1  Bollinger_Bands    Buy\n",
      "2              RSI   Flat \n",
      "\n",
      "------------- \n",
      "------------- Results Crossover -------------\n",
      "\n",
      "     function signal period_low period_mid period_high ema_low ema_mid  \\\n",
      "0  Crossover    Buy         25         50         200     NaN     NaN   \n",
      "\n",
      "  ema_high    ema1_now    ema2_now    ema3_now  \n",
      "0      NaN  432.187188  430.023366  417.012547   \n",
      "\n",
      "------------- \n",
      "------------- Results Bollinger Bands -------------\n",
      "\n",
      "           function signal period std  lower_band  middle_band  upper_band\n",
      "0  Bollinger_Bands    Buy     15   1  425.586317   436.358663  447.131009 \n",
      "\n",
      "------------- \n",
      "------------- Results RSI -------------\n",
      "\n",
      "   function signal period upper_level lower_level\n",
      "0      RSI   Flat     25          70          30 \n",
      "\n",
      "------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_8728\\1517949193.py:100: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.sma_bands_info = pd.concat([self.sma_bands_info, pd.DataFrame({\n"
     ]
    }
   ],
   "source": [
    "dh = DataHistory()\n",
    "df = dh.get_yahoo_data_history('MSFT', '1y', '1d')\n",
    "\n",
    "tm = TrendMetrics()\n",
    "tm.get_crossover(data=df, l1=25, l2=50, l3=200 )\n",
    "tm.get_sma_bands(data=df, length=15, std_dev=1)\n",
    "tm.get_rsi(data=df, length=25, overbought=70, oversold=30)\n",
    "\n",
    "print('------------- Results df -------------\\n\\n',tm.result_df,'\\n\\n------------- ')\n",
    "\n",
    "print('------------- Results Crossover -------------\\n\\n',tm.crossover_info,'\\n\\n------------- ')\n",
    "\n",
    "print('------------- Results Bollinger Bands -------------\\n\\n',tm.sma_bands_info,'\\n\\n------------- ')\n",
    "\n",
    "print('------------- Results RSI -------------\\n\\n',tm.rsi_info,'\\n\\n------------- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6.QtCore import Qt\n",
    "from PySide6.QtGui import QColor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
