{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_data_history(symbol : str, period : str, interval: str, start = '1900-01-01', end = datetime.now(), prepost : bool = True):\n",
    "        '''\n",
    "        Data collection from yahoo\n",
    "\n",
    "        Parameters:\n",
    "        period : str\n",
    "            Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max Either Use period parameter or use start and end\n",
    "        interval : str\n",
    "            Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo Intraday data cannot extend last 60 days\n",
    "        start: str\n",
    "            Download start date string (YYYY-MM-DD) or _datetime, inclusive. Default is 1900-01-01 E.g. for start=\"2020-01-01\", the first data point will be on \"2020-01-01\"\n",
    "        end: str\n",
    "            Download end date string (YYYY-MM-DD) or _datetime, exclusive. Default is now E.g. for end=\"2023-01-01\", the last data point will be on \"2022-12-31\"\n",
    "        prepost : bool\n",
    "            Include Pre and Post market data in results? Default is False\n",
    "        debug: bool\n",
    "            If passed as False, will suppress error message printing to console.\n",
    "        '''\n",
    "        yahoo_data_history = yf.Ticker(symbol).history(period=period, interval=interval, start=start, end=end, prepost=prepost)\n",
    "        return yahoo_data_history\n",
    "\n",
    "history = get_yahoo_data_history(symbol=\"MSFT\",period='1y', interval='1d', end = datetime.now(), prepost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned Data: {'data': {'companies': []}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the endpoint and your API key\n",
    "url = \"https://api.simplywall.st/graphql\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer sws:ZGE4YzBlNzItMTg2Ni00Y2Y5LWI3YTktYzAxODcyZGEwZjE3OmFjODUzODRhZDUzNGMwMzY=\",\n",
    "    \"Content-Type\": \"application/json\",  # Required for JSON body\n",
    "}\n",
    "\n",
    "# Define the GraphQL query and variables\n",
    "query = \"\"\"\n",
    "query Companies($exchange: String!, $offset: Int!, $limit: Int!) {\n",
    "  companies(exchange: $exchange, offset: $offset, limit: $limit) {\n",
    "    id\n",
    "    exchangeSymbol\n",
    "    tickerSymbol\n",
    "    name\n",
    "    marketCapUSD\n",
    "    primaryIndustry { name }\n",
    "    secondaryIndustry { name }\n",
    "    tertiaryIndustry { name }\n",
    "    market { name iso2 }\n",
    "    closingPrices\n",
    "    statements { name title area type value outcome description state severity outcomeName }\n",
    "    listings { id exchangeSymbol tickerSymbol name marketCapUSD primaryIndustry { name } secondaryIndustry { name } tertiaryIndustry { name } market { name iso2 } closingPrices }\n",
    "    owners { name type sharesHeld percentOfSharesOutstanding holdingDate periodStartDate periodEndDate }\n",
    "    insiderTransactions { type ownerName ownerType description tradeDateMin tradeDateMax shares priceMin priceMax transactionValue percentageSharesTraded }\n",
    "    members { age name title tenure compensation }\n",
    "    active classificationStatus\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Define the variables for the query\n",
    "variables = {\n",
    "    \"exchange\": \"NYSE\",  # Try changing to \"NYSE\" or another exchange\n",
    "    \"offset\": 20,         # Try adjusting this value (e.g., 10 or 20)\n",
    "    \"limit\": 100          # Adjust limit to fetch more results\n",
    "}\n",
    "\n",
    "# Create the request payload\n",
    "payload = {\n",
    "    \"query\": query,\n",
    "    \"variables\": variables\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        print(\"No companies found with the given parameters.\")\n",
    "    else:\n",
    "        print(\"Returned Data:\", data)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "\n",
    "class CandlesPatterns:\n",
    "    \"\"\"\n",
    "    Detect all candlestick patterns using TA-Lib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.result_candles_history_df = pd.DataFrame(columns=['Pattern', 'Signal', 'Relevance', 'Stoploss'])\n",
    "        self.result_candles_df = pd.DataFrame(columns=['Pattern', 'Signal', 'Relevance', 'Stoploss'])\n",
    "        \n",
    "        \n",
    "    def detect_pattern(self, data: pd.DataFrame, pattern_function, pattern_name: str):\n",
    "        \"\"\"\n",
    "        General method to detect a specific candlestick pattern.\n",
    "        \"\"\"\n",
    "        data_pass = data\n",
    "\n",
    "        detection = pattern_function(data_pass['Open'], data_pass['High'], data_pass['Low'], data_pass['Close'])\n",
    "\n",
    "        non_zero_detection = detection[detection != 0]\n",
    "        if not non_zero_detection.empty:\n",
    "            for date, signal in non_zero_detection.items():\n",
    "                # Cálculo do Stoploss baseado no padrão\n",
    "                if pattern_name in [\n",
    "                    \"doji\", \"dragonfly_doji\", \"gravestone_doji\", \"engulfing\",\n",
    "                    \"morning_star\", \"evening_star\", \"marubozu\", \"harami\",\n",
    "                    \"harami_cross\", \"kicking\", \"kicking_by_length\", \"tasuki_gap\",\n",
    "                    \"gap_side_by_side_white\", \"counter_attack\", \"piercing\",\n",
    "                    \"dark_cloud_cover\", \"tri_star\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'Low'],5) if signal > 0 else round(data_pass.loc[date, 'High'],5)\n",
    "                elif pattern_name in [\n",
    "                    \"morning_doji_star\", \"hammer\", \"inverted_hammer\",\n",
    "                    \"thrusting\", \"matching_low\", \"three_white_soldiers\",\n",
    "                    \"three_outside\", \"three_stars_in_south\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'Low'],5)\n",
    "                elif pattern_name in [\n",
    "                    \"evening_doji_star\", \"hanging_man\", \"shooting_star\",\n",
    "                    \"on_neck\", \"in_neck\", \"three_black_crows\",\n",
    "                    \"three_inside\", \"advance_block\", \"stalled_pattern\"\n",
    "                ]:\n",
    "                    stoploss = round(data_pass.loc[date, 'High'],5)\n",
    "                else:\n",
    "                    stoploss = None\n",
    "\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'Pattern': [pattern_name],\n",
    "                    'Signal': [signal],\n",
    "                    'Relevance': ['Flat'],\n",
    "                    'Stoploss': [stoploss],\n",
    "                }, index=[date])\n",
    "\n",
    "                self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
    "\n",
    "                self.result_candles_df = self.result_candles_df[self.result_candles_df['Pattern'] != pattern_name]\n",
    "                self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n",
    "\n",
    "        return detection\n",
    "\n",
    "    def doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDOJI, \"doji\")\n",
    "\n",
    "    def dragonfly_doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDRAGONFLYDOJI, \"dragonfly_doji\")\n",
    "\n",
    "    def gravestone_doji(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLGRAVESTONEDOJI, \"gravestone_doji\")\n",
    "\n",
    "    def engulfing(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLENGULFING, \"engulfing\")\n",
    "\n",
    "    def morning_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLMORNINGSTAR, \"morning_star\")\n",
    "\n",
    "    def evening_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLEVENINGSTAR, \"evening_star\")\n",
    "\n",
    "    def morning_doji_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMORNINGDOJISTAR, \"morning_doji_star\")\n",
    "\n",
    "    def evening_doji_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLEVENINGDOJISTAR, \"evening_doji_star\")\n",
    "\n",
    "    def hammer(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLHAMMER, \"hammer\")\n",
    "\n",
    "    def inverted_hammer(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLINVERTEDHAMMER, \"inverted_hammer\")\n",
    "\n",
    "    def hanging_man(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLHANGINGMAN, \"hanging_man\")\n",
    "\n",
    "    def shooting_star(self, data: pd.DataFrame):\n",
    "        return self.detect_pattern(data, talib.CDLSHOOTINGSTAR, \"shooting_star\")\n",
    "\n",
    "    def marubozu(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMARUBOZU, \"marubozu\")\n",
    "\n",
    "    def harami(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLHARAMI, \"harami\")\n",
    "\n",
    "    def harami_cross(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLHARAMICROSS, \"harami_cross\")\n",
    "\n",
    "    def spinning_top(self, data: pd.DataFrame):\n",
    "        '''\n",
    "        NEED FIBONACCI\n",
    "        '''\n",
    "        return self.detect_pattern(data, talib.CDLSPINNINGTOP, \"spinning_top\")\n",
    "\n",
    "    def kicking(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLKICKING, \"kicking\")\n",
    "\n",
    "    def kicking_by_length(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLKICKINGBYLENGTH, \"kicking_by_length\")\n",
    "\n",
    "    def tasuki_gap(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTASUKIGAP, \"tasuki_gap\")\n",
    "\n",
    "    def gap_side_by_side_white(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLGAPSIDESIDEWHITE, \"gap_side_by_side_white\")\n",
    "\n",
    "    def counter_attack(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLCOUNTERATTACK, \"counter_attack\")\n",
    "\n",
    "    def piercing(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLPIERCING, \"piercing\")\n",
    "\n",
    "    def dark_cloud_cover(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLDARKCLOUDCOVER, \"dark_cloud_cover\")\n",
    "\n",
    "    def tri_star(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTRISTAR, \"tri_star\")\n",
    "\n",
    "    def on_neck(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLONNECK, \"on_neck\")\n",
    "\n",
    "    def in_neck(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLINNECK, \"in_neck\")\n",
    "\n",
    "    def thrusting(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLTHRUSTING, \"thrusting\")\n",
    "\n",
    "    def matching_low(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLMATCHINGLOW, \"matching_low\")\n",
    "\n",
    "    def three_black_crows(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3BLACKCROWS, \"three_black_crows\")\n",
    "\n",
    "    def three_white_soldiers(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3WHITESOLDIERS, \"three_white_soldiers\")\n",
    "\n",
    "    def three_inside(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3INSIDE, \"three_inside\")\n",
    "\n",
    "    def three_outside(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3OUTSIDE, \"three_outside\")\n",
    "\n",
    "    def three_stars_in_south(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDL3STARSINSOUTH, \"three_stars_in_south\")\n",
    "\n",
    "    def advance_block(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLADVANCEBLOCK, \"advance_block\")\n",
    "\n",
    "    def stalled_pattern(self, data: pd.DataFrame):\n",
    "        # takeprofit = None\n",
    "        return self.detect_pattern(data, talib.CDLSTALLEDPATTERN, \"stalled_pattern\")\n",
    "\n",
    "    # def abandoned_baby(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLABANDONEDBABY, \"abandoned_baby\")\n",
    "\n",
    "    # def unique_3_river(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLUNIQUE3RIVER, \"unique_3_river\")\n",
    "\n",
    "    # def belt_hold(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLBELTHOLD, \"belt_hold\")\n",
    "\n",
    "    # def separating_lines(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLSEPARATINGLINES, \"Separating Lines\")\n",
    "\n",
    "    # def upside_gap_two_crows(self, data: pd.DataFrame):\n",
    "    #     return self.detect_pattern(data, talib.CDLUPSIDEGAP2CROWS, \"Upside Gap Two Crows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_28416\\45596638.py:56: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_28416\\45596638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.result_candles_history_df = pd.concat([self.result_candles_history_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_28416\\45596638.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n",
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_28416\\45596638.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.result_candles_df = pd.concat([self.result_candles_df, new_entry], ignore_index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Detected Patterns with Stoploss:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Stoploss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-18 00:00:00-04:00</th>\n",
       "      <td>advance_block</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>543.35483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-18 00:00:00-04:00</th>\n",
       "      <td>counter_attack</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>424.30297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-22 00:00:00-04:00</th>\n",
       "      <td>dark_cloud_cover</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>385.83253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>dragonfly_doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-02 00:00:00-04:00</th>\n",
       "      <td>engulfing</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>540.16963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-20 00:00:00-04:00</th>\n",
       "      <td>evening_doji_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>445.94876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26 00:00:00-05:00</th>\n",
       "      <td>evening_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>502.30678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24 00:00:00-05:00</th>\n",
       "      <td>gap_side_by_side_white</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>447.15793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28 00:00:00-04:00</th>\n",
       "      <td>gravestone_doji</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>517.76285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-17 00:00:00-04:00</th>\n",
       "      <td>hammer</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>522.25921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-06 00:00:00-04:00</th>\n",
       "      <td>hanging_man</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>530.28146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>harami</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 00:00:00-04:00</th>\n",
       "      <td>harami_cross</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.04680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-18 00:00:00-04:00</th>\n",
       "      <td>in_neck</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>428.77127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-24 00:00:00-04:00</th>\n",
       "      <td>inverted_hammer</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>539.14615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-03 00:00:00-04:00</th>\n",
       "      <td>marubozu</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.13756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13 00:00:00-04:00</th>\n",
       "      <td>matching_low</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>514.75201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-22 00:00:00-04:00</th>\n",
       "      <td>morning_doji_star</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>369.50890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12 00:00:00-04:00</th>\n",
       "      <td>morning_star</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>504.39007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-11 00:00:00-04:00</th>\n",
       "      <td>on_neck</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>505.39713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-25 00:00:00-04:00</th>\n",
       "      <td>piercing</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>421.58109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-18 00:00:00-04:00</th>\n",
       "      <td>shooting_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>510.53281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-21 00:00:00-04:00</th>\n",
       "      <td>spinning_top</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01 00:00:00-05:00</th>\n",
       "      <td>stalled_pattern</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>434.13640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 00:00:00-05:00</th>\n",
       "      <td>tasuki_gap</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>382.23807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-02 00:00:00-04:00</th>\n",
       "      <td>three_inside</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.49530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-03 00:00:00-04:00</th>\n",
       "      <td>three_outside</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>545.13756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-13 00:00:00-05:00</th>\n",
       "      <td>three_white_soldiers</td>\n",
       "      <td>100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>456.39155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01 00:00:00-04:00</th>\n",
       "      <td>thrusting</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>376.05613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-27 00:00:00-05:00</th>\n",
       "      <td>tri_star</td>\n",
       "      <td>-100</td>\n",
       "      <td>Flat</td>\n",
       "      <td>447.90530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Pattern Signal Relevance   Stoploss\n",
       "2024-06-18 00:00:00-04:00           advance_block   -100      Flat  543.35483\n",
       "2023-08-18 00:00:00-04:00          counter_attack    100      Flat  424.30297\n",
       "2022-07-22 00:00:00-04:00        dark_cloud_cover   -100      Flat  385.83253\n",
       "2024-07-01 00:00:00-04:00                    doji    100      Flat  539.04680\n",
       "2024-07-01 00:00:00-04:00          dragonfly_doji    100      Flat  539.04680\n",
       "2024-07-02 00:00:00-04:00               engulfing    100      Flat  540.16963\n",
       "2023-07-20 00:00:00-04:00       evening_doji_star   -100      Flat  445.94876\n",
       "2024-02-26 00:00:00-05:00            evening_star   -100      Flat  502.30678\n",
       "2023-11-24 00:00:00-05:00  gap_side_by_side_white    100      Flat  447.15793\n",
       "2024-03-28 00:00:00-04:00         gravestone_doji    100      Flat  517.76285\n",
       "2024-05-17 00:00:00-04:00                  hammer    100      Flat  522.25921\n",
       "2024-06-06 00:00:00-04:00             hanging_man   -100      Flat  530.28146\n",
       "2024-07-01 00:00:00-04:00                  harami    100      Flat  539.04680\n",
       "2024-07-01 00:00:00-04:00            harami_cross    100      Flat  539.04680\n",
       "2023-08-18 00:00:00-04:00                 in_neck   -100      Flat  428.77127\n",
       "2024-06-24 00:00:00-04:00         inverted_hammer    100      Flat  539.14615\n",
       "2024-07-03 00:00:00-04:00                marubozu    100      Flat  545.13756\n",
       "2024-05-13 00:00:00-04:00            matching_low    100      Flat  514.75201\n",
       "2021-03-22 00:00:00-04:00       morning_doji_star    100      Flat  369.50890\n",
       "2024-03-12 00:00:00-04:00            morning_star    100      Flat  504.39007\n",
       "2024-03-11 00:00:00-04:00                 on_neck   -100      Flat  505.39713\n",
       "2023-09-25 00:00:00-04:00                piercing    100      Flat  421.58109\n",
       "2024-03-18 00:00:00-04:00           shooting_star   -100      Flat  510.53281\n",
       "2024-06-21 00:00:00-04:00            spinning_top    100      Flat        NaN\n",
       "2022-02-01 00:00:00-05:00         stalled_pattern   -100      Flat  434.13640\n",
       "2022-11-14 00:00:00-05:00              tasuki_gap    100      Flat  382.23807\n",
       "2024-07-02 00:00:00-04:00            three_inside    100      Flat  545.49530\n",
       "2024-07-03 00:00:00-04:00           three_outside    100      Flat  545.13756\n",
       "2023-12-13 00:00:00-05:00    three_white_soldiers    100      Flat  456.39155\n",
       "2022-09-01 00:00:00-04:00               thrusting   -100      Flat  376.05613\n",
       "2023-11-27 00:00:00-05:00                tri_star   -100      Flat  447.90530"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "symbol = 'SPY'\n",
    "start, end = '2015-01-01', '2024-07-05'\n",
    "\n",
    "data = yf.Ticker(symbol).history(period='1y', interval='1d', start=start, end=end)\n",
    "\n",
    "cm = CandlesPatterns()\n",
    "\n",
    "# Loop para detectar padrões\n",
    "for candle_function in dir(cm):\n",
    "    if (not candle_function.startswith(\"__\") and \n",
    "        callable(getattr(cm, candle_function)) and \n",
    "        candle_function != \"detect_pattern\"):\n",
    "        pattern_function = getattr(cm, candle_function)\n",
    "        try:\n",
    "            candle_result = pattern_function(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting pattern {candle_function}: {e}\")\n",
    "\n",
    "# Verificar padrões detectados e valores de stoploss\n",
    "print(\"\\nAll Detected Patterns with Stoploss:\")\n",
    "cm.result_candles_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "\n",
    "class TrendMetrics():\n",
    "    \"\"\"\n",
    "    A class that encapsulates technical analysis metrics using TA-Lib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.result_df = pd.DataFrame(columns=['function', 'signal'])\n",
    "        self.crossover_info = pd.DataFrame(columns=['function', 'signal', 'period_low', 'period_mid', 'period_high', 'ema_low', 'ema_mid', 'ema_high'])\n",
    "        self.sma_bands_info = pd.DataFrame(columns=['function', 'signal', 'period', 'std', 'lower_band', 'middle_band', 'upper_band'])\n",
    "        self.rsi_info = pd.DataFrame(columns=['function', 'signal', 'period', 'upper_level', 'lower_level'])\n",
    "\n",
    "    def get_crossover(self, data: pd.DataFrame, l1: int, l2: int, l3: int):\n",
    "        \"\"\"\n",
    "        This function measures the crossover of 3 EMAs using TA-Lib.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - l1, l2, l3: Periods for the 3 EMAs.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.crossover_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "        period_low, period_mid, period_high = l1, l2, l3\n",
    "        \n",
    "        # Compute EMAs\n",
    "        ema1 = talib.EMA(data['Close'], timeperiod=l1)\n",
    "        ema2 = talib.EMA(data['Close'], timeperiod=l2)\n",
    "        ema3 = talib.EMA(data['Close'], timeperiod=l3)\n",
    "\n",
    "        # Current values\n",
    "        ema_low, ema_mid, ema_high = ema1.iloc[-1], ema2.iloc[-1], ema3.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if ema_low > ema_mid > ema_high:\n",
    "            crossover_signal = 'Buy'\n",
    "        elif ema_low < ema_mid < ema_high:\n",
    "            crossover_signal = 'Sell'\n",
    "        else:\n",
    "            crossover_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['Crossover'],\n",
    "            'signal': [crossover_signal]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        # Save result\n",
    "        self.crossover_info = pd.concat([self.crossover_info, pd.DataFrame({\n",
    "            'function': ['Crossover'],\n",
    "            'signal': [crossover_signal],\n",
    "            'period_low': [period_low],\n",
    "            'period_mid': [period_mid],\n",
    "            'period_high': [period_high],\n",
    "            'ema1_now': [ema_low],\n",
    "            'ema2_now': [ema_mid],\n",
    "            'ema3_now': [ema_high],\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    def get_sma_bands(self, data: pd.DataFrame, length: int=15, std_dev: int = 1):\n",
    "        \"\"\"\n",
    "        This function calculates Bollinger Bands and detects signals based on them.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - length: SMA period.\n",
    "        - std_dev: Number of standard deviations for the bands.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.bbands_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "\n",
    "        period, std = length, std_dev\n",
    "\n",
    "        # Compute Bollinger Bands\n",
    "        upper_band, middle_band, lower_band = talib.BBANDS(\n",
    "            data['Close'], timeperiod=length, nbdevup=std_dev, nbdevdn=std_dev, matype=0\n",
    "        )\n",
    "\n",
    "        # Current values\n",
    "        last_close = data['Close'].iloc[-1]\n",
    "        lower_band, middle_band, upper_band = lower_band.iloc[-1], middle_band.iloc[-1], upper_band.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if last_close <= lower_band:\n",
    "            bbands_signal = 'Buy'\n",
    "        elif last_close >= upper_band:\n",
    "            bbands_signal = 'Sell'\n",
    "        else:\n",
    "            bbands_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['Bollinger_Bands'],\n",
    "            'signal': [bbands_signal]\n",
    "        })], ignore_index=True)\n",
    "        \n",
    "        self.sma_bands_info = pd.concat([self.sma_bands_info, pd.DataFrame({\n",
    "            'function': ['Bollinger_Bands'],\n",
    "            'signal': [bbands_signal],\n",
    "            'period': [period],\n",
    "            'std': [std],\n",
    "            'lower_band': [lower_band],\n",
    "            'middle_band': [middle_band],\n",
    "            'upper_band': [upper_band]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    def get_rsi(self, data: pd.DataFrame, length: int = 25, overbought: int = 70, oversold: int = 30):\n",
    "        \"\"\"\n",
    "        This function calculates the RSI and generates a signal based on overbought/oversold levels.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: DataFrame containing the price data with a 'close' column.\n",
    "        - length: RSI period.\n",
    "        - overbought: RSI overbought threshold.\n",
    "        - oversold: RSI oversold threshold.\n",
    "        \n",
    "        Returns:\n",
    "        - Updates self.rsi_signal with 'Buy', 'Sell', or 'Flat'.\n",
    "        \"\"\"\n",
    "\n",
    "        period, upper_level, lower_level = length, overbought, oversold \n",
    "\n",
    "        # Compute RSI\n",
    "        rsi = talib.RSI(data['Close'], timeperiod=length)\n",
    "        rsi_now = rsi.iloc[-1]\n",
    "\n",
    "        # Determine signal\n",
    "        if rsi_now >= overbought:\n",
    "            rsi_signal = 'Sell'\n",
    "        elif rsi_now <= oversold:\n",
    "            rsi_signal = 'Buy'\n",
    "        else:\n",
    "            rsi_signal = 'Flat'\n",
    "\n",
    "        # Save result\n",
    "        self.result_df = pd.concat([self.result_df, pd.DataFrame({\n",
    "            'function': ['RSI'],\n",
    "            'signal': [rsi_signal]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        self.rsi_info = pd.concat([self.rsi_info, pd.DataFrame({\n",
    "            'function': ['RSI'],\n",
    "            'signal': [rsi_signal],\n",
    "            'period': [period],\n",
    "            'upper_level': [upper_level],\n",
    "            'lower_level': [lower_level]\n",
    "        })], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class ParamsOptimization():\n",
    "    \"\"\"\n",
    "    A class for optimizing technical indicators' parameters and evaluating strategy performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.crossover_params = pd.DataFrame(columns=['Ticker', 'EMA1', 'EMA2', 'EMA3', 'Sharpe', 'MaxDrawdown', 'Expectancy'])\n",
    "        self.bbands_params = pd.DataFrame(columns=['Ticker', 'Period', 'Std', 'Sharpe', 'MaxDrawdown', 'Expectancy'])\n",
    "\n",
    "    def optimize(self, asset_type: str, symbol: str, period: str, interval: str):\n",
    "        \"\"\"\n",
    "        Run optimization for all strategies.\n",
    "        \"\"\"\n",
    "        data = self.fetch_data(asset_type, symbol, period, interval)\n",
    "        self.crossover_results = self.optimize_crossover(data, symbol)\n",
    "        self.bbands_results = self.optimize_bbands(data, symbol)\n",
    "\n",
    "\n",
    "    def fetch_data(self,asset_type: str, symbol : str, period : str, interval : str):\n",
    "        \"\"\"\n",
    "        Simulate fetching market data for the given ticker. According to same periodicity and timeframe of subject bot setting\n",
    "        \"\"\"\n",
    "\n",
    "        if asset_type == 'stock':\n",
    "            from backend.datasources.yahoodata import DataHistory\n",
    "            dh = DataHistory()\n",
    "            data = dh.get_yahoo_data_history(symbol, period, interval, start=datetime.now(), end=datetime.now() - timedelta(days=365))\n",
    "\n",
    "        elif asset_type == 'cambial':\n",
    "            pass\n",
    "            # Metatrader\n",
    "        elif asset_type == 'crypto':\n",
    "            pass\n",
    "            # crypto\n",
    "        return data\n",
    "\n",
    "    def optimize_crossover(self, data : pd.DataFrame, symbol : str):\n",
    "        \"\"\"\n",
    "        Optimize EMA crossover strategy.\n",
    "        \"\"\"\n",
    "        ema1_periods = range(10, 21)\n",
    "        ema2_periods = range(25, 61)\n",
    "        ema3_periods = range(100, 200)\n",
    "\n",
    "        combinations = list(itertools.product(ema1_periods, ema2_periods, ema3_periods))\n",
    "\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.simulate_crossover)(\n",
    "            data, symbol, l1, l2, l3) for l1, l2, l3 in tqdm(combinations, desc=\"Optimizing EMA Crossover\"))\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def simulate_crossover(self, data : pd.DataFrame, symbol : str, l1 : int, l2 : int, l3 : int):\n",
    "        \"\"\"\n",
    "        Simulate crossover strategy and calculate metrics.\n",
    "        \"\"\"\n",
    "        # Calculate EMAs\n",
    "        data['ema1'] = talib.EMA(data['Close'], timeperiod=l1)\n",
    "        data['ema2'] = talib.EMA(data['Close'], timeperiod=l2)\n",
    "        data['ema3'] = talib.EMA(data['Close'], timeperiod=l3)\n",
    "\n",
    "        # Generate signals\n",
    "        data['signal'] = np.where((data['ema1'] > data['ema2']) & (data['ema2'] > data['ema3']), 1,\n",
    "                                  np.where((data['ema1'] < data['ema2']) & (data['ema2'] < data['ema3']), -1, 0))\n",
    "        data['returns'] = data['Close'].pct_change() * data['signal'].shift(1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        sharpe = self.calculate_sharpe(data['returns'])\n",
    "        max_drawdown = self.calculate_max_drawdown(data['returns'])\n",
    "        expectancy = self.calculate_expectancy(data['returns'])\n",
    "\n",
    "        return {\n",
    "            'Ticker': symbol,\n",
    "            'EMA1': l1,\n",
    "            'EMA2': l2,\n",
    "            'EMA3': l3,\n",
    "            'Sharpe': sharpe,\n",
    "            'MaxDrawdown': max_drawdown,\n",
    "            'Expectancy': expectancy\n",
    "        }\n",
    "\n",
    "    def optimize_bbands(self, data : pd.DataFrame, symbol : str):\n",
    "        \"\"\"\n",
    "        Optimize Bollinger Bands strategy.\n",
    "        \"\"\"\n",
    "        sma_periods = range(10, 21)\n",
    "        std_devs = range(1, 3)\n",
    "\n",
    "        combinations = list(itertools.product(sma_periods, std_devs))\n",
    "\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.simulate_bbands)(\n",
    "            data, symbol, period, std) for period, std in tqdm(combinations, desc=\"Optimizing Bollinger Bands\"))\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "       \n",
    "        return results_df\n",
    "\n",
    "    def simulate_bbands(self, data, symbol, period, std):\n",
    "        \"\"\"\n",
    "        Simulate Bollinger Bands strategy and calculate metrics.\n",
    "        \"\"\"\n",
    "        # Calculate Bollinger Bands\n",
    "        upperband, middleband, lowerband = talib.BBANDS(\n",
    "            data['Close'], timeperiod=period, nbdevup=std, nbdevdn=std, matype=0\n",
    "        )\n",
    "\n",
    "        # Generate signals\n",
    "        data['signal'] = np.where(data['Close'] < lowerband, 1,\n",
    "                                  np.where(data['Close'] > upperband, -1, 0))\n",
    "        data['returns'] = data['Close'].pct_change() * data['signal'].shift(1)\n",
    "\n",
    "        # Calculate metrics\n",
    "        sharpe = self.calculate_sharpe(data['returns'])\n",
    "        max_drawdown = self.calculate_max_drawdown(data['returns'])\n",
    "        expectancy = self.calculate_expectancy(data['returns'])\n",
    "\n",
    "        return {\n",
    "            'Ticker': symbol,\n",
    "            'Period': period,\n",
    "            'Std': std,\n",
    "            'Sharpe': sharpe,\n",
    "            'MaxDrawdown': max_drawdown,\n",
    "            'Expectancy': expectancy\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_sharpe(returns, risk_free_rate=0.025):\n",
    "        \"\"\"\n",
    "        Calculate Sharpe Ratio.\n",
    "        \"\"\"\n",
    "        mean_return = returns.mean()\n",
    "        std_dev = returns.std()\n",
    "        if std_dev == 0:\n",
    "            return 0\n",
    "        return (mean_return - risk_free_rate) / std_dev\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_max_drawdown(returns):\n",
    "        \"\"\"\n",
    "        Calculate Max Drawdown.\n",
    "        \"\"\"\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        running_max = cumulative.cummax()\n",
    "        drawdown = running_max - cumulative\n",
    "        return drawdown.max()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_expectancy(returns):\n",
    "        \"\"\"\n",
    "        Calculate Expectancy.\n",
    "        \"\"\"\n",
    "        wins = returns[returns > 0]\n",
    "        losses = returns[returns < 0]\n",
    "        win_rate = len(wins) / len(returns) if len(returns) > 0 else 0\n",
    "        loss_rate = 1 - win_rate\n",
    "        avg_win = wins.mean() if len(wins) > 0 else 0\n",
    "        avg_loss = losses.mean() if len(losses) > 0 else 0\n",
    "        return (win_rate * avg_win) - (loss_rate * avg_loss)\n",
    "\n",
    "# Adicionar Fontes Crypt e Cambial\n",
    "# Adicionar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_28416\\1446340434.py:100: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.sma_bands_info = pd.concat([self.sma_bands_info, pd.DataFrame({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bollinger_Bands</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crossover</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RSI</td>\n",
       "      <td>Flat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          function signal\n",
       "0  Bollinger_Bands   Sell\n",
       "1        Crossover    Buy\n",
       "2              RSI   Flat"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data\n",
    "\n",
    "tm = TrendMetrics()\n",
    "tm.get_sma_bands(data=df, length=15, std_dev=1)\n",
    "tm.get_crossover(data=df, l1=25, l2=50, l3=200)\n",
    "tm.get_rsi(data=df, length=25, overbought=70, oversold=30)\n",
    "\n",
    "tm.result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing EMA Crossover: 100%|██████████| 39600/39600 [00:11<00:00, 3312.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Otimização EMA Crossover:\n",
      "      Ticker  EMA1  EMA2  EMA3    Sharpe  MaxDrawdown  Expectancy\n",
      "0        SPY    10    25   100 -2.613950     0.303667    0.006992\n",
      "1        SPY    10    25   101 -2.617432     0.300424    0.006995\n",
      "2        SPY    10    25   102 -2.630023     0.290087    0.006981\n",
      "3        SPY    10    25   103 -2.633408     0.292406    0.006980\n",
      "4        SPY    10    25   104 -2.634544     0.300940    0.006974\n",
      "...      ...   ...   ...   ...       ...          ...         ...\n",
      "39595    SPY    20    60   195 -2.871977     0.474086    0.006832\n",
      "39596    SPY    20    60   196 -2.871949     0.477427    0.006837\n",
      "39597    SPY    20    60   197 -2.872561     0.474437    0.006838\n",
      "39598    SPY    20    60   198 -2.875468     0.465207    0.006835\n",
      "39599    SPY    20    60   199 -2.876874     0.472461    0.006831\n",
      "\n",
      "[39600 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Bollinger Bands: 100%|██████████| 22/22 [00:00<00:00, 10994.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados da Otimização Bollinger Bands:\n",
      "   Ticker  Period  Std    Sharpe  MaxDrawdown  Expectancy\n",
      "0     SPY      10    1 -2.962345     0.420373    0.006978\n",
      "1     SPY      10    2 -6.799412     0.157983    0.008256\n",
      "2     SPY      11    1 -2.860866     0.533861    0.007054\n",
      "3     SPY      11    2 -6.456669     0.159455    0.007891\n",
      "4     SPY      12    1 -2.809079     0.583004    0.007035\n",
      "5     SPY      12    2 -6.246475     0.123052    0.008021\n",
      "6     SPY      13    1 -2.814964     0.554000    0.007008\n",
      "7     SPY      13    2 -5.855324     0.119517    0.007864\n",
      "8     SPY      14    1 -2.840845     0.575541    0.006970\n",
      "9     SPY      14    2 -5.917115     0.113973    0.007216\n",
      "10    SPY      15    1 -2.854063     0.562334    0.006926\n",
      "11    SPY      15    2 -5.924271     0.115390    0.007134\n",
      "12    SPY      16    1 -2.840299     0.513837    0.006951\n",
      "13    SPY      16    2 -5.921385     0.123770    0.007015\n",
      "14    SPY      17    1 -2.838378     0.523457    0.006951\n",
      "15    SPY      17    2 -5.839987     0.123308    0.007007\n",
      "16    SPY      18    1 -2.849458     0.572846    0.006901\n",
      "17    SPY      18    2 -5.761735     0.110701    0.006851\n",
      "18    SPY      19    1 -2.836316     0.579756    0.006881\n",
      "19    SPY      19    2 -5.854253     0.139096    0.006782\n",
      "20    SPY      20    1 -2.831535     0.594481    0.006845\n",
      "21    SPY      20    2 -5.820352     0.082902    0.006642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instanciar a classe\n",
    "optimizer = ParamsOptimization()\n",
    "\n",
    "# Testar otimização de EMA crossover\n",
    "crossover_results = optimizer.optimize_crossover(data, symbol=symbol)\n",
    "print(\"Resultados da Otimização EMA Crossover:\")\n",
    "print(crossover_results)\n",
    "\n",
    "# Testar otimização de Bollinger Bands\n",
    "bbands_results = optimizer.optimize_bbands(data, symbol=symbol)\n",
    "print(\"\\nResultados da Otimização Bollinger Bands:\")\n",
    "print(bbands_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection Binance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.binance.com/api/v3/ticker/price\"\n",
    "params = {\"symbol\": \"BTCUSDT\"}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    symbol = response.json()[\"symbol\"]\n",
    "    price = response.json()[\"price\"]\n",
    "else:\n",
    "    error = response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_crypto_symbol_24h(symbol : str):\n",
    "\n",
    "    url = \"https://api.binance.com/api/v3/ticker/24hr\"\n",
    "    params = {\"symbol\": symbol}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        priceChangePercent = Decimal(response.json()[\"priceChangePercent\"])\n",
    "        weightedAvgPrice = Decimal(response.json()[\"weightedAvgPrice\"])\n",
    "        prevClosePrice = Decimal(response.json()[\"prevClosePrice\"])\n",
    "        priceChange = Decimal(response.json()[\"priceChange\"])\n",
    "        lastPrice = Decimal(response.json()[\"lastPrice\"])\n",
    "        lastQty = Decimal(response.json()[\"lastQty\"])\n",
    "        bidPrice = Decimal(response.json()[\"bidPrice\"])\n",
    "        bidQty = Decimal(response.json()[\"bidQty\"])\n",
    "        askPrice = Decimal(response.json()[\"askPrice\"])\n",
    "        askQty = Decimal(response.json()[\"askQty\"])\n",
    "        openPrice = Decimal(response.json()[\"openPrice\"])\n",
    "        highPrice = Decimal(response.json()[\"highPrice\"])\n",
    "        lowPrice = Decimal(response.json()[\"lowPrice\"])\n",
    "        volume = Decimal(response.json()[\"volume\"])\n",
    "        quoteVolume = Decimal(response.json()[\"quoteVolume\"])\n",
    "        openTime = datetime.fromtimestamp(response.json()[\"openTime\"] / 1000).strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "        closeTime = datetime.fromtimestamp(response.json()[\"closeTime\"] / 1000).strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "        firstId = response.json()[\"firstId\"]\n",
    "        lastId = response.json()[\"lastId\"]\n",
    "        count = response.json()[\"count\"]\n",
    "    else:\n",
    "        print(f\"Erro: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lastId'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_crypto_symbol_24h\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBTCUSDT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlastId\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lastId'"
     ]
    }
   ],
   "source": [
    "get_crypto_symbol_24h(\"BTCUSDT\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
